<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[面试准备笔记整理]]></title>
    <url>%2FJava%2FPrepare-For-Java-Interview-detail.html</url>
    <content type="text"><![CDATA[Java集合框架Collection├List│├LinkedList│├ArrayList│└Vector│ └Stack└Set└QueueMap├Hashtable├HashMap└WeakHashMap 重点要分清数组与链表的特点： 快速随机访问(RandomAccess)： RandomAccess 接口是一个标志接口，本身并没有提供任何方法，任务凡是通过调用 RandomAccess 接口的对象都可以认为是支持快速随机访问的对象。此接口的主要目的是标识那些可支持快速随机访问的 List 实现。任何一个基于数组的 List 实现都实现了 RaodomAccess 接口，而基于链表的实现则都没有。因为只有数组能够进行快速的随机访问，而对链表的随机访问需要进行链表的遍历。因此，此接口的好处是，可以在应用程序中知道正在处理的 List 对象是否可以进行快速随机访问，从而针对不同的 List 进行不同的操作，以提高程序的性能。 线程安全： ArrayList 与 LinkedList 对比， HashMap取值的时间复杂度 平衡树、红黑树 JVM 此处所有的JVM讨论都是基于JDK自带的Hotspot的JVM。 客户模式或服务器模式JIT 编译器在运行程序时有两种编译模式可以选择，并且其会在运行时决定使用哪一种以达到最优性能。这两种编译模式的命名源自于命令行参数（eg: -client 或者 -server）。JVM Server 模式与 client 模式启动，最主要的差别在于：-server 模式启动时，速度较慢，但是一旦运行起来后，性能将会有很大的提升。原因是：当虚拟机运行在-client 模式的时候，使用的是一个代号为 C1 的轻量级编译器，而-server 模式启动的虚拟机采用相对重量级代号为 C2 的编译器。C2 比 C1 编译器编译的相对彻底，服务起来之后，性能更高。 通过 java -version 命令行可以直接查看当前系统使用的是 client 还是 server 模式。 JVM内存模型： 按照JVM规范，JAVA虚拟机在运行时会管理以下的内存区域： 程序计数器：当前线程执行的字节码的行号指示器，线程私有 JAVA虚拟机栈：Java方法执行的内存模型，每个Java方法的执行对应着一个栈帧的进栈和出栈的操作。 本地方法栈：类似“ JAVA虚拟机栈 ”，但是为native方法的运行提供内存环境。 JAVA堆：对象内存分配的地方，内存垃圾回收的主要区域，所有线程共享。可分为新生代，老生代。 方法区：用于存储已经被JVM加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。Hotspot中的“永久代”。 注意：这里的永久代(PermanentSpace)针对jdk1.7之前的版本，JDK1.7常量已经放在Heap分区，JDK8中则完全移除了PermanentSpace，InternedStrings也被放到了MetaSpace（元空间）中 运行时常量池：方法区的一部分，存储常量信息，如各种字面量、符号引用等。 直接内存：并不是JVM运行时数据区的一部分， 可直接访问的内存， 比如NIO会用到这部分。 按照JVM规范，除了程序计数器不会抛出OOM外，其他各个内存区域都可能会抛出OOM。 判断对象存活状态根路径搜索算法(GC-Root-trancing)如果对象与GC-Root之间不可达，则认为该对象可回收解决了引用计数器方法不能回收两个循环引用但无外部引用的对象这一问题 三种GC算法： 标记-清除算法(Mark-sweep) （老年代）分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记对象。缺点：1）产生大量不连续的内存碎片2）标记和清除效率都不高 复制算法(Copying) （新生代）它将可用内存按照容量划分为大小相等的两块，每次只使用其中一块。当这一块的内存用完了，则就将还存活的对象复制到另一块上面，然后再把已经使用过的内存空间一次清理掉。使得每次都是对整个半区进行内存回收。 优点：1）不会出现内存碎片。2）只需移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。 缺点：1）将内存缩小为原来的一半。2）在对象存活率较高时会进行较多复制操作，效率较低。 商业虚拟机的分配担保机制：将内存分为一块较大的 eden 空间和两块较小的 survivor 空间，默认比例是 8:1:1，即每次新生代中可用内存空间为整个新生代容量的 90%，每次使用 eden 和其中一个 survivour。当回收时，将 eden 和 survivor 中还存活的对象一次性复制到另外一块 survivor 上，最后清理掉 eden 和刚才用过的 survivor，若另外一块 survivor 空间没有足够内存空间存放上次新生代收集下来的存活对象时，这些对象将直接通过分配担保机制进入老年代。 标记-整理算法(Mark-Compact) （老年代）标记过程和“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清除，而是让所有存活对象都向一端移动，然后直接清理掉端边界以外的内存。 七种收集器： Serial （复制算法） ParNew （复制算法） Parallel Scavenge （复制算法） 并行 CMS(Concurrent Mark Sweep ) （标记-清除） 并发 Serial Old(MSC) （标记-整理） Parallel Old （标记-整理）并行 G1 （分块 总体看是标记-整理 每块都是复制算法） 最常见的OOM情况有以下三种： java.lang.OutOfMemoryError: Java heap space ——&gt;java堆内存溢出，此种情况最常见，一般由于内存泄露或者堆的大小设置不当引起。对于内存泄露，需要通过内存监控软件查找程序中的泄露代码，而堆大小可以通过虚拟机参数-Xms,-Xmx等修改。 java.lang.OutOfMemoryError: PermGen space ——&gt;java永久代溢出，即方法区溢出了，一般出现于大量Class或者jsp页面，或者采用cglib等反射机制的情况，因为上述情况会产生大量的Class信息存储于方法区。此种情况可以通过更改方法区的大小来解决，使用类似-XX:PermSize=64m -XX:MaxPermSize=256m的形式修改。另外，过多的常量尤其是字符串也会导致方法区溢出。 java.lang.StackOverflowError ——&gt; 不会抛OOM error，但也是比较常见的Java内存溢出。JAVA虚拟机栈溢出，一般是由于程序中存在死循环或者深度递归调用造成的，栈大小设置太小也会出现此种溢出。可以通过虚拟机参数-Xss来设置栈的大小。 OOM分析: –heapdump 设置JVM参数-XX:+HeapDumpOnOutOfMemoryError，设定当发生OOM时自动dump出堆信息。不过该方法需要JDK5以上版本。 使用JDK自带的jmap命令。”jmap -dump:format=b,file=heap.bin “ 其中pid可以通过jps获取。 dump堆内存信息后，需要对dump出的文件进行分析，从而找到OOM的原因。常用的工具有： mat: eclipse memory analyzer, 基于eclipse RCP的内存分析工具。详细信息参见：http://www.eclipse.org/mat/， 推荐使用。 jhat：JDK自带的java heap analyze tool，可以将堆中的对象以html的形式显示出来，包括对象的数量，大小等等，并支持对象查询语言OQL，分析相关的应用后，可以通过http://localhost:7000 来访问分析结果。不推荐使用，因为在实际的排查过程中，一般是先在生产环境 dump出文件来，然后拉到自己的开发机器上分析，所以，不如采用高级的分析工具比如前面的mat来的高效。 Plumbr 如何减少GC出现的次数： 对象不用时显示置null。 少用System.gc()。 尽量少用静态变量。 尽量使用StringBuffer，而不用String累加字符串。 分散对象创建或删除的时间。 少用finalize函数。 如果需要使用经常用到的图片，可以使用软引用类型，它可以尽可能将图片保存在内存中，供程序调用，而不引起OOM。 能用基本类型就不用基本类型封装类。 增大-Xmx的值。 反射 java的反射机制主要是指程序可以访问，检测和修改它本身状态或行为的一种能力，并能根据自身行为的状态和结果，调整或修改应用所描述行为的状态和相关的语义。反射是java中一种强大的工具，能够使我们很方便的创建灵活的代码，这些代码可以再运行时装配，无需在组件之间进行源代码链接。但是反射使用不当会成本很高！ 从代码中可以看出，先检查 AccessibleObject的override属性是否为true（override属性默认为false）。AccessibleObject是Method,Field,Constructor的父类,可调用setAccessible方法改变，如果设置为true,则表示可以忽略访问权限的限制，直接调用。如果不是ture,则要进行访问权限检测。用Reflection的quickCheckMemberAccess方法先检查是不是public的，如果不是再用Reflection.getCallerClass()方法获得到调用这个方法的Class,然后做是否有权限访问的校验，校验之后缓存一次，以便下次如果还是这个类来调用就不用去做校验了，直接用上次的结果。 简而言之，通过反射，我们可以在运行时获得程序或程序集中每一个类型的成员和成员的信息。程序中一般的对象的类型都是在编译期就确定下来的，而 Java 反射机制可以动态地创建对象并调用其属性，这样的对象的类型在编译期是未知的。所以我们可以通过反射机制直接创建对象，即使这个对象的类型在编译期是未知的。 反射的核心是 JVM 在运行时才动态加载类或调用方法/访问属性，它不需要事先（写代码的时候或编译期）知道运行对象是谁。 Java 反射主要提供以下功能： 在运行时判断任意一个对象所属的类； 在运行时构造任意一个类的对象； 在运行时判断任意一个类所具有的成员变量和方法（通过反射甚至可以调用private方法）； 在运行时调用任意一个对象的方法 由于反射会额外消耗一定的系统资源，因此如果不需要动态地创建一个对象，那么就不需要用反射。 另外，反射调用方法时可以忽略权限检查，因此可能会破坏封装性而导致安全问题。 AOP (aspect-oriented programming 面向切面编程) 面向切面编程的思想里面，把功能分为核心业务功能，和周边功能． 业务代码:登录登出，增删改查， 周边代码:权限检查，日志管理，事务管理，性能检查(方法执行耗时) AOP能够将那些与业务无关，却为业务模块所共同调用的逻辑或责任（例如事务处理、日志管理、权限控制等）封装起来，便于减少系统的重复代码，降低模块间的耦合度，并有利于未来的可拓展性和可维护性。本质：代理模式 代理增强一般会用到Spring的动态代理库CGLib或者JDK自带的动态代理库，注意一个细节是如果被代理的对象没有抽象接口，则不能用JDK代理，而Spring AOP没有这个限制另一个细节是Spring AOP有一个@DeclareParents引介增强注解可以为Bean引入另一个Bean的方法 Spring Spring框架四大模块： Data:提供了一些数据相关的组件：包括JDBC、orm（对象关系映射）、事务操作、oxm（对象xml映射）、Jms（Java消息服务）。 WEB:扩展了Spring的Web功能。使其符合MVC的设计规范，最重要的是提供了Spring MVC的容器。 AOP:负责Spring的所有AOP（面向切面）的功能。(日志，事务) Core Container:核心容器，从核心俩字我们可以看出，这是Spring最重要的部分。主要的功能是实现了控制反转（IOC）与依赖注入（DI）、Bean配置、加载以及生命周期的管理。 Spring IOC控制反转，依赖注入Factory生成代理bean时机，依赖注入时机 注入方式： 构造器注入 setter注入 接口注入 Spring cloud了解Spring cloud之前需要先了解下什么是微服务 微服务（Micro Service）:微服务是一种架构风格，一个大型复杂软件应用由一个或多个微服务组成。系统中的各个微服务可被独立部署，各个微服务之间是松耦合的。每个微服务仅关注于完成一件任务并很好地完成该任务。在所有情况下，每个任务代表着一个小的业务能力。 微服务为什么会出现？ 大型整体式应用维护困难。 传统架构升级困难。 新的轻量级协议(RESTful)、容器化(Docker)的出现。 Spring Cloud是一套用于微服务的、简单易懂、易部署和易维护的分布式系统开发工具包。它利用Spring Boot的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，都可以用Spring Boot的开发风格做到一键启动和部署。 Spring Cloud如何实现微服务？ Eureka（注册中心）：负责所有微服务的管理。 Ribbon（服务发现）：主要负责客户端的负载均衡 Feign（接口伪装）：使微服务之间的调用像本地调用一样简单。 Hystrix（熔断处理）：在微服务出现问题时防止出现雪崩效应。 Zuul（代理机制）：安全认证、动态路由、流量管理、服务器负载均衡 Config（配置管理）：管理所有微服务的配置文件（GIT/SVN）。 DobboSQL善用 explain执行计划 事务事务属性（ACID） 原子性（Atomicity）：事务是一个原子操作单元。在当时原子是不可分割的最小元素，其对数据的修改，要么全部成功，要么全部都不成功。 一致性（Consistent）：事务开始到结束的时间段内，数据都必须保持一致状态。 隔离性（Isolation）：数据库系统提供一定的隔离机制，保证事务在不受外部并发操作影响的”独立”环境执行。 持久性（Durable）：事务完成后，它对于数据的修改是永久性的，即使出现系统故障也能够保持。 事务常见问题 更新丢失（Lost Update）原因：当多个事务选择同一行操作，并且都是基于最初选定的值，由于每个事务都不知道其他事务的存在，就会发生更新覆盖的问题。类比github提交冲突。 脏读（Dirty Reads）原因：事务A读取了事务B已经修改但尚未提交的数据。若事务B回滚数据，事务A的数据存在不一致性的问题。 不可重复读（Non-Repeatable Reads）原因：事务A第一次读取最初数据，第二次读取事务B已经提交的修改或删除数据。导致两次读取数据不一致。不符合事务的隔离性。 幻读（Phantom Reads）原因：事务A根据相同条件第二次查询到事务B提交的新增数据，两次数据结果集不一致。不符合事务的隔离性。 幻读和脏读有点类似脏读是事务B里面修改了数据，幻读是事务B里面新增了数据。 隔离级别 隔离级别 读数据一致性 脏读 不可重复读 幻读 未提交读(Read uncommitted) 最低级别 是 是 是 已提交读(Read committed) 语句级 否 是 是 可重复读(Repeatable read) 事务级 否 否 是 可序列化(Serializable) 最高级别，事务级 否 否 否 行锁与表锁行锁行锁的劣势：开销大；加锁慢；会出现死锁行锁的优势：锁的粒度小，发生锁冲突的概率低；处理并发的能力强加锁的方式：自动加锁。对于UPDATE、DELETE和INSERT语句，InnoDB会自动给涉及数据集加排他锁；对于普通SELECT语句，InnoDB不会加任何锁；当然我们也可以显示的加锁：共享锁：’select 语句 + lock in share more’排他锁：’select 语句 + for update’InnoDB和MyISAM的最大不同点有两个：一，InnoDB支持事务(transaction)；二，默认采用行级锁。加锁可以保证事务的一致性， 间隙锁(GAP) (Next-Key锁) 排他锁 也称写锁，独占锁。当前写操作没有完成前，它会阻断其他写锁和读锁。 共享锁 也称读锁，多用于判断数据是否存在，多个读操作可以同时进行而不会互相影响。当如果事务对读锁进行修改操作，很可能会造成死锁。 表锁 共享读锁不会阻塞其他进程对同一表的读操作，但会阻塞对同一表的写操作。只有当读锁释放后，才能执行其他进程的写操作。在锁释放前不能取其他表。 独占写锁会阻塞其他进程对同一表的读和写操作，只有当写锁释放后，才会执行其他进程的读写操作。在锁释放前不能写其他表。 总结 InnoDB 支持表锁和行锁，使用索引作为检索条件修改数据时采用行锁，否则采用表锁。 InnoDB 自动给修改操作加锁，给查询操作不自动加锁 行锁可能因为未使用索引而升级为表锁，所以除了检查索引是否创建的同时，也需要通过explain执行计划查询索引是否被实际使用。 行锁相对于表锁来说，优势在于高并发场景下表现更突出，毕竟锁的粒度小。 当表的大部分数据需要被修改，或者是多表复杂关联查询时，建议使用表锁优于行锁。 为了保证数据的一致完整性，任何一个数据库都存在锁定机制。锁定机制的优劣直接影响到一个数据库的并发处理能力和性能。 多线程两种重要的锁：synchronized lock volatile 轻量级，只保证修改同步和可见性，不保证线程安全 IO模型BIO，NIO，AIO]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>面试</tag>
        <tag>Interview</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试准备大纲]]></title>
    <url>%2FJava%2FPrepare-For-Java-Interview.html</url>
    <content type="text"><![CDATA[数据结构 集合 数组 String 基本数据类型与对应实例对象(装箱和拆箱) java基础 各种修饰符 关键字 反射 AOP(注解) 代理 泛型 多线程 JVM 常用设计模式单例模式，工厂模式，观察者模式, 装饰器模式，代理模式，职责链模式， 五大io模型 常用框架或中间件 Spring(IOC) Spring Boot. Spring mybatis. Shiro Zookeeper. rabbitmq. kafka. elasticsearch. RPC(Dobbo) Spring cloud. 数据库相关 mysql, postgresql, DynamoDB, MongoDB, Redis, Memcached]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>面试</tag>
        <tag>Interview</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot整合Elastic Job简单实践Demo]]></title>
    <url>%2FJava%2Felastic-job-with-spring-boot-demo.html</url>
    <content type="text"><![CDATA[简介 Elastic-Job是一个分布式调度解决方案，由两个相互独立的子项目Elastic-Job-Lite和Elastic-Job-Cloud组成。Elastic-Job-Lite定位为轻量级无中心化解决方案，使用jar包的形式提供最轻量级的分布式任务的协调服务，外部依赖仅Zookeeper。 你可以在官方文档页面了解更多信息．此处就不详细介绍了． 关于ZookeeperElastic Job依赖Zookeeper作为调度中心协调任务的分片和调度以支持分布式，所以我们首先需要搭建一个Zookeeper环境.由于这不是本文的重点，此处就不详细介绍了．为了体现其高可用和高效率的特点，一般需要三个Zookeeper节点组成集群．这里由于只是验证性的Demo，因此我是在本地搭建的单节点Zookeeper注册中心．简述一下Linux下的安装过程： 下载Zookeeper的安装包，然后解压到/opt目录．这里下载的是 3.4.10 版本． 1tar zxvf zookeeper-3.4.10.tar.gz -C /opt 在/opt目录新建zk_data和zk_logs 两个目录，并赋777权限12mkdir zk_data zk_logschmod 777 zk_data zk_logs 在Zookeeper的解压目录中/conf目录下新建zoo.cfg文件．123456789101112131415161718192021222324252627282930# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial# synchronization phase can takeinitLimit=10# The number of ticks that can pass between# sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just# example sakes.dataDir=/opt/zk_datadataLogDir=/opt/zk_logs# the port at which the clients will connectclientPort=2181server.1=127.0.0.1:2888:3888# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the# administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to "0" to disable auto purge feature#autopurge.purgeInterval=1 启动Zookeeper服务,在/opt/zookeeper-3.4.10/bin/目录下执行1zkServer.sh start 查看状态1zkServer.sh status 你还可以：配置全局命令编辑.bashrc(如果你使用zsh那么编辑.zshrc)添加一下配置以支持全局命令：.bashrc和.zshrc一般在home文件夹下12export ZOOKEEPER_HOME=/opt/zookeeper-3.4.10export PATH=$ZOOKEEPER_HOME/bin:$PATH 以上，单机Zookeeper就配置好了． 添加Maven 依赖123456789101112131415161718192021222324252627282930313233&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;version&gt;1.4.2.RELEASE&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!-- 引入elastic-job-lite核心模块 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.dangdang&lt;/groupId&gt; &lt;artifactId&gt;elastic-job-lite-core&lt;/artifactId&gt; &lt;version&gt;2.0.5&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 使用springframework自定义命名空间时引入 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.dangdang&lt;/groupId&gt; &lt;artifactId&gt;elastic-job-lite-spring&lt;/artifactId&gt; &lt;version&gt;2.0.5&lt;/version&gt;&lt;/dependency&gt; 编辑配置文件application.properties123456789101112131415161718#elastic jobzookeeper.serviceLists=127.0.0.1:2181zookeeper.namespace=anduin-elastic-job-testzookeeper.baseSleepTimeMilliseconds=5000zookeeper.maxSleepTimeMilliseconds=5000zookeeper.maxRetries=3#定时任务simpleJob.mySimpleJob.name=mySimpleJob# Seconds Minutes Hours Day-of-Month Month Day-of-Week Year (可选字段)simpleJob.mySimpleJob.cron=*/10 * * * * ?simpleJob.mySimpleJob.shardingTotalCount=1demo.demoJob.name=demoJobdemo.demoJob.cron=*/5 * * * * ?demo.demoJob.shardingTotalCount=1 新建ZookeeperConfig配置类以Spring Boot注解的方式配置Zookeeper，12345678910111213141516171819202122232425262728293031323334353637383940414243package com.zobgo.job.javaconfig;import com.dangdang.ddframe.job.reg.zookeeper.ZookeeperConfiguration;import com.dangdang.ddframe.job.reg.zookeeper.ZookeeperRegistryCenter;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * Created by zongbo.zhang on 8/15/18.*/@Configurationpublic class ZookeeperConfig &#123; @Value("$&#123;zookeeper.serviceLists&#125;") private String serviceLists; @Value("$&#123;zookeeper.namespace&#125;") private String nameSpace; @Value("$&#123;zookeeper.baseSleepTimeMilliseconds&#125;") private int baseSleepTimeMilliseconds; @Value("$&#123;zookeeper.maxSleepTimeMilliseconds&#125;") private int maxSleepTimeMilliseconds; @Value("$&#123;zookeeper.maxRetries&#125;") private int maxRetries; /** * zookeeper 配置 * @return */ @Bean(initMethod = "init") public ZookeeperRegistryCenter zookeeperRegistryCenter()&#123; ZookeeperConfiguration configuration = new ZookeeperConfiguration(serviceLists,nameSpace); configuration.setBaseSleepTimeMilliseconds(baseSleepTimeMilliseconds); configuration.setMaxSleepTimeMilliseconds(maxSleepTimeMilliseconds); configuration.setMaxRetries(maxRetries); return new ZookeeperRegistryCenter(configuration); &#125;&#125; 新建一个DemoJob类．这个一个SimpleJob的实现类，具体的Job逻辑在这里实现，这个DemoJob的工作就是打印一条日志1234567891011121314151617181920212223242526272829package com.zobgo.job.demo;import com.dangdang.ddframe.job.api.ShardingContext;import com.dangdang.ddframe.job.api.simple.SimpleJob;import org.springframework.stereotype.Component;import lombok.extern.slf4j.Slf4j;/** * Created by zongbo.zhang on 8/23/18. */@Slf4j@Componentpublic class DemoJob implements SimpleJob &#123; @Override public void execute(ShardingContext shardingContext) &#123; log.info("&lt;====Demo Job Begin====&gt;"); log.info(String.format("------Thread ID: %s, 任务总片数: %s, 当前分片项: %s", Thread.currentThread().getId(), shardingContext.getShardingTotalCount(), shardingContext.getShardingItem())); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; log.info("&lt;====Demo Job End====&gt;"); &#125;&#125; 新建DemoConfig配置类DemoConfig是对DemoJob的配置，包括注册中心，Cron表达式，分片数，任务监听器等123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package com.zobgo.job.javaconfig;import com.dangdang.ddframe.job.config.JobCoreConfiguration;import com.dangdang.ddframe.job.config.simple.SimpleJobConfiguration;import com.dangdang.ddframe.job.lite.api.JobScheduler;import com.dangdang.ddframe.job.lite.config.LiteJobConfiguration;import com.dangdang.ddframe.job.lite.spring.api.SpringJobScheduler;import com.dangdang.ddframe.job.reg.zookeeper.ZookeeperRegistryCenter;import com.zobgo.job.demo.DemoJob;import com.zobgo.job.listener.MyElasticJobListener;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import javax.annotation.Resource;/** * Created by zongbo.zhang on 8/23/18. */@Configurationpublic class DemoConfig &#123; @Resource private ZookeeperRegistryCenter registryCenter; @Value("$&#123;demo.demoJob.name&#125;") private String demoJobName; @Value("$&#123;demo.demoJob.cron&#125;") private String demoJobCron; @Value("$&#123;demo.demoJob.shardingTotalCount&#125;") private int demoJobShardingTotalCount; @Bean public DemoJob demoJob()&#123; return new DemoJob(); &#125; @Bean(initMethod = "init") public JobScheduler demoJobScheduler(final DemoJob demoJob)&#123; MyElasticJobListener elasticJobListener = new MyElasticJobListener(); return new SpringJobScheduler(demoJob,registryCenter,liteJobConfiguration(),elasticJobListener); &#125; private LiteJobConfiguration liteJobConfiguration()&#123; return LiteJobConfiguration.newBuilder( new SimpleJobConfiguration( JobCoreConfiguration.newBuilder(demoJobName,demoJobCron,demoJobShardingTotalCount).build() ,DemoJob.class.getCanonicalName() )).overwrite(true).build(); &#125;&#125; 新建MyElasticJobListener Job监听器，可以在Job开始和结束时进行一些操作，比如Job结束时发送一封邮件，这里的监听器的作用是统计Job的执行耗时123456789101112131415161718192021222324252627282930313233343536373839package com.zobgo.job.listener;import com.dangdang.ddframe.job.executor.ShardingContexts;import com.dangdang.ddframe.job.lite.api.listener.ElasticJobListener;import com.zogbo.common.utils.TimeUtil;import java.util.Date;import lombok.extern.slf4j.Slf4j;/** * Created by zongbo.zhang on 8/17/18. * * 任务总监听器 */@Slf4jpublic class MyElasticJobListener implements ElasticJobListener&#123; private long beginTime = 0; @Override public void beforeJobExecuted(ShardingContexts shardingContexts) &#123; beginTime = System.currentTimeMillis(); log.info("===&gt;&#123;&#125; JOB BEGIN TIME: &#123;&#125; &lt;===",shardingContexts.getJobName(), TimeUtil.mill2Time(beginTime)); &#125; @Override public void afterJobExecuted(ShardingContexts shardingContexts) &#123; long endTime = System.currentTimeMillis(); log.info("===&gt;&#123;&#125; JOB END TIME: &#123;&#125;,TOTAL CAST: &#123;&#125; &lt;===",shardingContexts.getJobName(), TimeUtil.mill2Time(endTime), endTime - beginTime); &#125; public static void main(String[] args) &#123; System.out.println(TimeUtil.mill2Time(System.currentTimeMillis())); &#125;&#125; 对了，这里用到了我在Util中实现的一个TimeUtil.mill2Time方法，就是一个很简单的把Unix TimeStamp时间格式化为年月日时间的类 1234public static String mill2Time(long mill)&#123; SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss SSS"); return sdf.format(mill); &#125; 新建启动类AnduinJobApplicationSpring Boot的启动类JobApplication 123456789101112131415161718192021package com.zobgo;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.ComponentScan;import lombok.extern.slf4j.Slf4j;/** * Created by zongbo.zhang on 8/16/18. */@SpringBootApplication@Slf4j@ComponentScan(basePackages = &#123;"com.zobgo"&#125;)public class AnduinJobApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(AnduinJobApplication.class,args); &#125;&#125; 项目目录结构： 项目中用到了@Slf4j 如果日志接口导致不能运行，则把log.info换成System.out.println();成功运行，效果如下: 简单实践假设有这样一个场景： 有一张用户评论表comment，table comment中有一个comment_status字段标识该条评论的删除状态：0 - 删除 | 1 - 正常，由于某种原因，一直有评论需要从删除状态恢复到正常状态(假设有这种奇怪的需求)．0 -&gt; 1，这时就需要一个定时任务，每隔一定时间扫描一次table,然后找出所有的需要修改的评论，更新其状态为1，这时就可以考虑用Elastic Job来实现．comment表如图： 轮询修改数据库的定时任务MySimpleJob12345678910111213141516171819202122232425262728293031323334353637package com.zobgo.job.simple;import com.zobgo.business.comment.model.Comment;import com.zobgo.business.comment.service.api.CommentService;import com.dangdang.ddframe.job.api.ShardingContext;import com.dangdang.ddframe.job.api.simple.SimpleJob;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.Lazy;import org.springframework.stereotype.Component;import java.util.ArrayList;import java.util.List;import lombok.extern.slf4j.Slf4j;/** * Created by zongbo.zhang on 8/15/18. */@Slf4j@Componentpublic class MySimpleJob implements SimpleJob &#123; @Autowired @Lazy CommentService commentService; @Override public void execute(ShardingContext shardingContext) &#123; List&lt;Comment&gt; comments = commentService.getCommentByStatus(0); log.info("待更新条数： &#123;&#125;",comments.size()); List&lt;Long&gt; commentIds = new ArrayList&lt;&gt;(); comments.forEach(comment -&gt; commentIds.add(comment.getCommentId())); commentService.updateCommentByCommentIds(Byte.valueOf("1"),commentIds); log.info("更新了: &#123;&#125;条记录", comments.size()); &#125;&#125; 当然，和上面的Demo一样，还需要一个定时任务的配置类 轮询修改数据库的定时任务的配置类MySimpleConfig12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package com.zobgo.job.javaconfig;import com.dangdang.ddframe.job.config.JobCoreConfiguration;import com.dangdang.ddframe.job.config.simple.SimpleJobConfiguration;import com.dangdang.ddframe.job.lite.api.JobScheduler;import com.dangdang.ddframe.job.lite.config.LiteJobConfiguration;import com.dangdang.ddframe.job.lite.spring.api.SpringJobScheduler;import com.dangdang.ddframe.job.reg.zookeeper.ZookeeperRegistryCenter;import com.zobgo.job.listener.MyElasticJobListener;import com.zobgo.job.simple.MySimpleJob;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import javax.annotation.Resource;/** * Created by zongbo.zhang on 8/16/18. */@Configurationpublic class MySimpleConfig &#123; @Resource private ZookeeperRegistryCenter registryCenter; @Value("$&#123;simpleJob.mySimpleJob.name&#125;") private String mySimpleJobName; @Value("$&#123;simpleJob.mySimpleJob.cron&#125;") private String mySimpleJobCron; @Value("$&#123;simpleJob.mySimpleJob.shardingTotalCount&#125;") private int mySimpleJobShardingTotalCount; @Bean public MySimpleJob mySimpleJob()&#123; return new MySimpleJob(); &#125; @Bean(initMethod = "init") public JobScheduler mySimpleJobScheduler(final MySimpleJob mySimpleJob)&#123; MyElasticJobListener elasticJobListener = new MyElasticJobListener(); return new SpringJobScheduler(mySimpleJob,registryCenter, liteJobConfiguration(), elasticJobListener); &#125; private LiteJobConfiguration liteJobConfiguration()&#123; //定义Lite作业根配置 return LiteJobConfiguration.newBuilder(new SimpleJobConfiguration( JobCoreConfiguration.newBuilder(mySimpleJobName,mySimpleJobCron,mySimpleJobShardingTotalCount).build(), MySimpleJob.class.getCanonicalName() )).overwrite(true).build(); &#125;&#125; 至于Mybatis相关的Dao操作，和commentService中对comment具体的筛选与操作逻辑，由于不是本文重点，此处就不贴代码了．具体的项目源码已上传到Github，可以前往查看． 运行结果]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Elastic Job</tag>
        <tag>Zookeeper</tag>
        <tag>定时任务</tag>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Excel中财务函数PV,PMT公式的java实现]]></title>
    <url>%2FJava%2Fpv-pmt-expression-in-excel-java-code.html</url>
    <content type="text"><![CDATA[PV 是一个财务函数，用于根据固定利率计算贷款或投资的现值。 可以将 PV 与定期付款、固定付款（如按揭或其他贷款）或投资目标的未来值结合使用。 语法PV(rate, nper, pmt, [fv], [type]) 参数PV 函数语法具有下列参数： Rate 必需。 各期利率。 例如，如果您获得年利率为 10% 的汽车贷款，并且每月还款一次，则每月的利率为 10%/12（即 0.83%）。 您需要在公式中输入 10%/12（即 0.83%）或 0.0083 作为利率。 Nper 必需。 年金的付款总期数。 例如，如果您获得为期四年的汽车贷款，每月还款一次，则贷款期数为 4*12（即 48）期。 您需要在公式中输入 48 作为 nper。 Pmt 必需。 每期的付款金额，在年金周期内不能更改。 通常，pmt 包括本金和利息，但不含其他费用或税金。 例如，对于金额为 ￥100,000、利率为 12% 的四年期汽车贷款，每月付款为 ￥2633.30。 您需要在公式中输入 -2633.30 作为 pmt。 如果省略 pmt，则必须包括 fv 参数。 fv 可选。 未来值，或在最后一次付款后希望得到的现金余额。 如果省略 fv，则假定其值为 0（例如，贷款的未来值是 0）。 例如，如果要在 18 年中为支付某个特殊项目而储蓄 ￥500,000，则 ￥500,000 就是未来值。 然后，您可以对利率进行保守的猜测，并确定每月必须储蓄的金额。 如果省略 fv，则必须包括 pmt 参数。 类型 可选。 数字 0 或 1，用以指定各期的付款时间是在期初还是期末。 公式Microsoft Excel 根据其他参数来求解某个金融参数。 如果 rate 不为 0，则： 如果 rate 为 0，则： (pmt * nper) + pv + fv = 0 文档 以上是Office 的 support 文档对PV计算的部分介绍,详细可以看看Office文档 java代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package com.insurance.common.utill;import java.math.BigDecimal;/** * Created by zhangzb on 2018/06/26. */public class PMTUtil &#123; public static double pmtRoundDown(double monthRate,int periods,double amount)&#123; double var = Math.pow(1 + monthRate,periods); double pmtAmount = amount * (monthRate * var) / (var - 1); return new BigDecimal(pmtAmount).setScale(2, BigDecimal.ROUND_DOWN).doubleValue(); &#125; public static double pmt(double monthRate,int periods,double amount,int percise)&#123; double var = Math.pow(1 + monthRate,periods); double pmtAmount = amount * (monthRate * var) / (var - 1); return new BigDecimal(pmtAmount).setScale(percise, BigDecimal.ROUND_HALF_UP).doubleValue(); &#125; //参考 https://support.office.com/zh-CN/article/PV-%E5%87%BD%E6%95%B0-23879D31-0E02-4321-BE01-DA16E8168CBD public static double pv(double monthRate,int periods,double peridsAmount)&#123; /** * 如果年化收益率为零，monthRate作分母会出现NaN错误，需要对月利率为零进行特殊处理 */ if (monthRate == 0)&#123; return periods * peridsAmount; &#125; double var = Math.pow(1 + monthRate,-periods); double pvAmount = (peridsAmount - peridsAmount * var) / monthRate; return new BigDecimal(pvAmount).setScale(2, BigDecimal.ROUND_HALF_UP).doubleValue(); &#125; public static void main(String[]args)&#123; System.out.println(pmt(0.115/12,12,10000,2)); System.out.println(PMTUtil.pv(0.08 / 12,5,662.12)); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>pv</tag>
        <tag>pmt</tag>
        <tag>excel</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux解决unzip中文乱码]]></title>
    <url>%2FLinux%2Flinux-chinese-unzip-Garbled.html</url>
    <content type="text"><![CDATA[linux解压神器：unar 用过linux的同学可能多多少少接触过linux下文档的压缩归档，通常来说我们最喜欢的还是用tar命令进行文件的归档。可有些时候，我们也不得不面对windows下常用压缩格式.zip文档。这时候同学们最先想到的肯定就是linux自带的unzip，使用命令unzip files.zip解压.zip文档一气呵成，合情合理。unzip命令在大多数情况下也不会让我们失望。解压过程优雅迅捷。可是随着我们继续使用unzip，我们会发现一个unzip致命的缺陷：当.zip包中有中文命名的文件时，解压出来的文件名会乱码。效果如图： 网上有人给出了原因： 原因是unzip试图将zip文件中用 oem(ibm-dos) codepage 编码的文件名转换成自己的内部编码。可惜unzip只能转换极少数几种codepage，中文的 cp936 不在其列。 甚至还给出了解决方案： 修改unzip的源码：在unzip.cpp源文件的ZRESULT TUnzip::Get方法。 重新编译unzip，在编译时指定参数：make -DExt_ASCII_TO_Native。 解压时指定参数：类似与这样unzip -O CP936 xxx.zip (GBK, GB18030也可以)。 以上方法有些过于复杂，有些实测没有效果。这里不予推荐。这里推荐的是：12sudo apt install unarunar xxx.zip 使用unar后，解压中文就不会出现乱码啦，效果如图：]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>乱码</tag>
        <tag>Garbled</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客进阶--SEO优化]]></title>
    <url>%2FHexo%2Fhexo-search-engine-optimization.html</url>
    <content type="text"><![CDATA[搜索引擎优化（英语：search engine optimization，缩写为SEO），是一种通过了解搜索引擎的运作规则来调整网站，以及提高目的网站在有关搜索引擎内排名的方式。由于不少研究发现，搜索引擎的用户往往只会留意搜索结果最前面的几个条目，所以不少网站都希望通过各种形式来影响搜索引擎的排序，让自己的网站可以有优秀的搜索排名。当中尤以各种依靠广告维生的网站为甚。 优化你的urlseo搜索引擎优化认为，网站的最佳结构是用户从首页点击三次就可以到达任何一个页面，但是我们使用hexo编译的站点打开文章的url是：sitename/year/mounth/day/title四层的结构，这样的url结构很不利于seo，爬虫就会经常爬不到我们的文章，于是，我们可以将url直接改成sitename/title的形式，并且title最好是用英文，在站点配置文件下修改permalink如下： 1234url: https://www.zobgo.comroot: /permalink: :title.htmlpermalink_defaults: 注意：修改后文章的阅读量和评论会被清空，原因在于leanCloud的文章评论和阅读量是根据文章title和path记录的，之前文章阅读量和文章评论还绑定在旧的路径下．解决方法是打开leancloud，修改对应文章的路径 修改前路径：1/2018/05/17/hello-world/ 修改后路径：1/hello-world/ 这样评论和访问量就能正常显示了 添加站点地图sitemap.xml 安装sitemap站点地图自动生成插件 12$ npm install hexo-generator-sitemap --save$ npm install hexo-generator-baidu-sitemap --save 在主题配置文件中添加一下配置 12345sitemap: path: sitemap.xmlbaidusitemap: path: baidusitemap.xml 然后在站点配置文件中修改url为你的域名 1234# URL## If your site is put in a subdirectory, set url as &apos;http://yoursite.com/child&apos; and root as &apos;/child/&apos;url: https://zobgo.comroot: / 配置完成后，1$ hexo g 会在your-hexo-site\public 中生成sitemap.xml 和 baidusitemap.xml;其中sitemap.xml是一会要提交给google的，baidusitemap.xml当然就是提交给Baidu的了； 在your-hexo-site/source中新建文件robots.txt,内容如下： 请把其中我的域名换成你自己的 123456789101112131415User-agent: *Allow: /Allow: /archives/Allow: /categories/Allow: /tags/Disallow: /vendors/Disallow: /js/Disallow: /css/Disallow: /fonts/Disallow: /vendors/Disallow: /fancybox/Sitemap: https://zobgo.com/sitemap.xmlSitemap: https://zobgo.com/baidusitemap.xml 给非友情链接的出站链接添加 “nofollow” 标签参考这篇博文nofollow的目的是防止搜索引擎spider在爬取我们的站点时，从外链出逃到别的站点，这对我们的站点是不利的。所以我们要对友情链接等外链进行标记，禁止spider出逃。 登录google webmaster 并验证你的站点你有两种比较常用的方式验证你的站点： 上传HTML以验证 上传HTML，顾名思义，就是往你的站点根目录上传一个谷歌提供的html网页，以验证你是站点的所有者，操作很简单，注意顺序： 下载HTML验证文件 先hexo g生成一次，然后将文件拷贝到站点目录的source目录下 hexo d发布你的站点 访问验证文件（ 我的是 https://www.zobgo.com/google55174e28c4588446.html 已删除换用标记验证）确认上传成功，回到google search console完成验证。 这个方法有两个需要注意的地方:第一，文件必须放在站点的source目录下，对应站点的根路径。第二，要在hexo g生成之后拷贝文件，拷贝之后不能再执行hexo g，原因是hexo g时会对html文件进行样式的格式化，这样google webmaster无法验证，如果你访问验证网页时发现此页面有hexo主题的样式，那你将会验证失败 HTML标记验证 此方法hexo-theme-next已集成，推荐此方法。 首先获取 google site verification code，登录 Google Webmaster Tools，导航到验证方法，并选择 HTML Tag。将会获取到一段代码：&lt;meta name=&quot;google-site-verification&quot; content=&quot;XXXXXXXXXXXXXXXXXXXXXXX&quot; /&gt;将 content 里面的 XXXXXXXXXXXXXXXXXXXXXXX 复制出来。如下图： 修改站点配置文件_config.yml，新增字段 google_site_verification：1google_site_verification: XXXXXXXXXXXXXXXXXXXXXXX 提交你的sitemap.xml登录google webmaster，在对应位置提交sitemap 如图所示： 测试提交robots.txt提交之前先点击测试按钮，已允许之后方可提交，我已经提交过了，看下图 接下来就可以静静等待google索引我们的网站了，你也可以手动 提交索引请求： Google 抓取方式抓取–google抓取工具 输入url，选择桌面或者移动设备，开始抓取出现完成，部分完成，已重定向这三种结果时，就可以提交请求编入索引了 通过SEO优化，在谷歌搜索文章标题，我们的文章排在搜索结果的第一位：]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>SEO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo-next接入评论和搜索服务]]></title>
    <url>%2FHexo%2Fhexo-next-add-comment-and-search.html</url>
    <content type="text"><![CDATA[添加阅读量展示：使用LeanCloud hexo-next 6.0 集成了leancloud_visitors firestore busuanzi_count 三种统计插件，这里我们选择leanCloud在完成注册LeanCloud帐号并验证邮箱之后，登录我们的LeanCloud帐号，进行简单的配置之后拿到AppID以及AppKey这两个参数就可以可正常使用文章阅读量统计的功能了。 注册LeanCloud：完成了注册和激活邮箱，接下来我们需要进入控制台创建一个应用 创建应用这里我已经创建过一个test应用（你可以随意起名），直接点进去 建立class:点击控制台的存储标签，我们需要一个名为Counter的class，注意这里不要自定class的名字，必须为Counter 绑定AppID和AppKey:打开控制台的设置标签栏，应用Key查看我们的应用Key复制AppID以及AppKey并在NexT主题的_config.yml文件中我们相应的位置填入即可，正确配置之后文件内容像这个样子:1234leancloud_visitors: enable: true app_id: dxDMdMpg9PkOb6M9tTxy7CNS-gzGzoHsz app_key: MExhCaDhpuIdy9kLiTVLFoz3 这个时候重新生成部署Hexo博客，应该就可以正常使用文章阅读量统计的功能了。需要特别说明的是：记录文章访问量的唯一标识符是文章的发布日期以及文章的标题，因此请确保这两个数值组合的唯一性，如果你更改了这两个数值，会造成文章阅读数值的清零重计。最后，一定要在Leancloud -&gt; 设置 -&gt; 安全中心 -&gt; Web 安全域名 把你的域名加进去，防止你的LeanCloud应用被恶意利用。 添加评论展示：使用ValineValine的简介是: 一款快速、简洁且高效的无后端评论系统。 你也可以使用 多说 畅言 网易云跟帖 来比力 hypercomments Gitment disqus 这里我简单总结一下上面这些第三方评论服务的优缺点：多说，网易云跟帖已经先后在2017年3月，7月停止服务。搜狐畅言需要备案，disqus被墙，gitment仅支持github用户。来比力是韩国的，国内有时会不稳定。hypercomments在官网体验时感觉不错，但是貌似收费，没仔细研究，也可能是我没发现免费入口。valine的界面和Next主题很搭，国内访问速度很快，唯一的缺点就是评论不能添加图片(经评论提醒，是可以评论图片的) valine 也是基于LeanCloud的免费云服务进行的开发。跟上面的添加阅读量统计很类似，如果你已经接入过LeanCloud的阅读量统计，那么接下来就很简单了 让我们三步完成评论服务的接入：创建Comment Class：让我们回到LeanCloud在我们刚才建的test应用中新建一个名叫 Comment 的Class，注意，这个Class也不要自定名称，只能使用Comment修改NexT主题的_config.yml文件：12345678910valine: enable: true appid: dxDMdMpg9PkOb6M9tTxy7CNS-gzGzoHsz appkey: MExhCaDhpuIdy9kLiTVLFoz3 notify: false # 邮件通知 verify: false # Verification code placeholder: just go go #输入框提示语 avatar: wavatar # 头像风格 guest_info: nick,mail # 昵称，邮箱 pageSize: 10 # 每页展示条数 接入Valine评论完成效果如下： 如果还有什么不懂的，可以去看看Valine官方文档 添加站内搜索：使用LocalSearch安装hexo-generator-searchdb plugin进入到你的站点根目录，在此处开始安装1$ npm install hexo-generator-searchdb --save 修改站点配置文件_config.yml在站点配置文件任意位置添加以下配置：12345search: path: search.xml field: post format: html limit: 10000 修改主题配置文件_config.yml找到主题配置文件的local_search项，将其更改为：1234567local_search: enable: true # if auto, trigger search by changing input # if manual, trigger search by pressing enter key or search button trigger: auto # show top n results per article, show all results by setting to -1 top_n_per_article: 1 大功告成，效果如下：]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>commnet</tag>
        <tag>search</tag>
        <tag>评论</tag>
        <tag>搜索</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[云南移动app加密]]></title>
    <url>%2FJava%2Fyun-nan-china-mobile-app-encrypt.html</url>
    <content type="text"><![CDATA[登录需要用到的加密字段 Fields encrypt mode password des cbc jsonParam Base64 md5sign Md5 密码加密123password = EncryptGZipUtils.encode(EncryptGZipUtils.desEncode(secret, password.getBytes("UTF-8"))); jsonParam加密123456String data = "[&#123;\"dynamicURI\":\"/login\",\"dynamicParameter\":&#123;\"method\":\"ln\",\"m\":\""+ mobile +"\",\"p\":\""+ password + "\",\"deviceCode\":\"\"&#125;,\"dynamicDataNodeName\":\"pwdLogin_node\"&#125;]";String jsonParam = Base64.encode(data.getBytes("GBK")); 请求体中的md5sign123final String MD5_KEY = "11100android!@#";String Md5Sign = Md5Util.toMd5(MD5_KEY + deviceId + jsonParam); 登录密码加密util1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283package com.zhangzb.utils;import com.alibaba.fastjson.JSON;import com.alibaba.fastjson.JSONObject;import javax.crypto.Cipher;import javax.crypto.spec.IvParameterSpec;import javax.crypto.spec.SecretKeySpec;import java.io.UnsupportedEncodingException;/** * Created by zhangzb on 17-8-2. */public class EncryptGZipUtils &#123; public static final int ACTION_MASK = 255; private static final char[] legalChars = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/".toCharArray(); private static byte[] iv = new byte[]&#123;(byte) 1, (byte) 2, (byte) 3, (byte) 4, (byte) 5, (byte) 6, (byte) 7, (byte) 8&#125;; public static String encode(byte[] data) &#123; int len = data.length; StringBuffer buf = new StringBuffer((data.length * 3) / 2); int end = len - 3; int i = 0; int n = 0; int d; while (i &lt;= end) &#123; d = (((data[i] &amp; ACTION_MASK) &lt;&lt; 16) | ((data[i + 1] &amp; ACTION_MASK) &lt;&lt; 8)) | (data[i + 2] &amp; ACTION_MASK); buf.append(legalChars[(d &gt;&gt; 18) &amp; 63]); buf.append(legalChars[(d &gt;&gt; 12) &amp; 63]); buf.append(legalChars[(d &gt;&gt; 6) &amp; 63]); buf.append(legalChars[d &amp; 63]); i += 3; int n2 = n + 1; if (n &gt;= 14) &#123; n2 = 0; buf.append(" "); &#125; n = n2; &#125; if (i == (0 + len) - 2) &#123; d = ((data[i] &amp; ACTION_MASK) &lt;&lt; 16) | ((data[i + 1] &amp; ACTION_MASK) &lt;&lt; 8); buf.append(legalChars[(d &gt;&gt; 18) &amp; 63]); buf.append(legalChars[(d &gt;&gt; 12) &amp; 63]); buf.append(legalChars[(d &gt;&gt; 6) &amp; 63]); buf.append("="); &#125; else if (i == (0 + len) - 1) &#123; d = (data[i] &amp; ACTION_MASK) &lt;&lt; 16; buf.append(legalChars[(d &gt;&gt; 18) &amp; 63]); buf.append(legalChars[(d &gt;&gt; 12) &amp; 63]); buf.append("=="); &#125; return buf.toString(); &#125; public static byte[] desEncode(String secret, byte[] byteS) &#123; try &#123; IvParameterSpec zeroIv = new IvParameterSpec(iv); SecretKeySpec key = new SecretKeySpec(secret.getBytes(), "DES"); Cipher cipher = Cipher.getInstance("DES/CBC/PKCS5Padding"); cipher.init(1, key, zeroIv); return cipher.doFinal(byteS); &#125; catch (Exception e) &#123; e.printStackTrace(); return null; &#125; &#125; public static void main(String[] args) &#123; String pwd = "82**88"; String secret = "!@#j*&amp;!k"; try &#123; String secretPwd = encode(EncryptGZipUtils.desEncode(secret, pwd.getBytes("UTF-8"))); System.out.println(secretPwd); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>encrypt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java发送邮件工具类]]></title>
    <url>%2FJava%2Fjava-send-mail-util.html</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243package com.zhangzob.util;import lombok.Data;import lombok.extern.slf4j.Slf4j;import org.simplejavamail.email.Email;import org.simplejavamail.mailer.Mailer;import javax.mail.Message;import java.util.List;import java.util.Map;/** * Created by zhangzb on 17-2-10. */@Slf4j@Datapublic class SendEmailUtil &#123; /** * @param map 要发送的消息 * @param toUser 收件人邮箱 */ public static void sendEmail(Map&lt;String, List&lt;String&gt;&gt; map, String toUser)&#123; StringBuilder stringBuilder = new StringBuilder(); for(String value : map.keySet())&#123; stringBuilder.append(value); stringBuilder.append(":"); stringBuilder.append(map.get(value).toString()); stringBuilder.append("\n"); &#125; Email email = new Email(); email.setFromAddress("apiTest", "yourmail@163.com"); email.addRecipient("", toUser, Message.RecipientType.TO); email.setSubject("测试结果"); email.setText(stringBuilder.toString()); new Mailer("smtp.163.com", 25, "yourmail@163.com", "yourPassword").sendMail(email); log.info("发送成功！"); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>mail</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fpost%2Fhello-world.html</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post.Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
