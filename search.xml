<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[面试准备笔记整理]]></title>
    <url>%2FJava%2FPrepare-For-Java-Interview-detail.html</url>
    <content type="text"><![CDATA[Java集合框架Collection├List│├LinkedList│├ArrayList│└Vector│ └Stack└Set└QueueMap├Hashtable├HashMap└WeakHashMap 重点要分清数组与链表的特点： 数组链表的优缺点： 数组占用空间小，链表元素还要包含上一元素和下一个元素的的信息 数组的访问速度快，因为内存是连续的 数组内部元素可以随机访问，而链表依赖于上一个元素的信息 链表的插入删除操作由于数组，因为内存不连续，只需要更改元素的前后节点信息就行了，并不需要更改元素内存地址，而数组的连续内存想要插入和删除的话就要移动所有的内存地址链表的内存利用率高于数组，链表内存是分散的一个元素占用一块空间，数组元素少于内存空间的话，会有部分的内存浪费；链表的扩展性强，数组的创建完成内存大小就确定了，满了就没法扩展只能再次创建新的数组，而链表可以随意的增加扩展 效率：数组查询效率高，链表增，删效率高 众所周知,数组的长度是固定的，无法对数组进行扩容，那么ArrayList和HashMap是怎样实现动态扩容的呢？生成一个更大的数组，然后把旧数组的元素拷贝进去ArrayList 默认会在容量不足时进行1.5倍的扩容而HashMap会根据加载因子（默认为0.75，容量到达总容量的0.75时，进行扩容），扩容后容量默认为2倍 快速随机访问(RandomAccess)：ArrayList,HashMap RandomAccess 接口是一个标志接口，本身并没有提供任何方法，任务凡是通过调用 RandomAccess 接口的对象都可以认为是支持快速随机访问的对象。此接口的主要目的是标识那些可支持快速随机访问的 List 实现。任何一个基于数组的 List 实现都实现了 RaodomAccess 接口，而基于链表的实现则都没有。因为只有数组能够进行快速的随机访问，而对链表的随机访问需要进行链表的遍历。因此，此接口的好处是，可以在应用程序中知道正在处理的 List 对象是否可以进行快速随机访问，从而针对不同的 List 进行不同的操作，以提高程序的性能。 线程安全： Vector, Stack, HashTable, ConcurrentHashMap HashTable由于多线程环境下性能低下，现在已经不建议使用，多线程环境下建议使用ConcurrentHashMap。ConcurrentHashMap对比HashTable的优化在于分段锁，引入了segment概念，segment本质是一个ReentrantLock(可重入锁),每个segment只锁住ConcurrentHashMap中的一部分元素在多线程取数据时，如果取的数据是不同segment管理下的数据，那么就不存在锁的竞争，故能大幅度提高效率ConcurrentHashMap计算Size:；理论上是segment块求和，但是存在求和过程中变化，这里有一个类似乐观锁的操作：因为在累加count操作过程中，之前累加过的count发生变化的几率非常小，所以ConcurrentHashMap的做法是先尝试2次通过不锁住Segment的方式来统计各个Segment大小，如果统计的过程中，容器的count发生了变化，则再采用加锁的方式来统计所有Segment的大小。 ArrayList 与 LinkedList 对比， HashMap取值的时间复杂度:理想状态下是O(1)，实际会发生hash碰撞，看遍历链表或者红黑树的时间复杂度怎样才能达到理想的时间复杂度？思路就是让元素尽可能的均匀分布，减少hash冲突：手段有：1. 优化Hash算法，减少Hash碰撞 ２． 增大桶容量，从而减少Hash碰撞HashMap实质是元素为链表的数组：java ８，优化之后在链表长度超过８之后会将链表转为红黑树，以提高查询效率（体现在红黑树查询效率比链表高） 为什么长度为８时转为红黑树？根据统计之后的链表长度的泊松分布，超过8的很少。 平衡树、红黑树 JVM 此处所有的JVM讨论都是基于JDK自带的Hotspot的JVM。 客户模式或服务器模式JIT 编译器在运行程序时有两种编译模式可以选择，并且其会在运行时决定使用哪一种以达到最优性能。这两种编译模式的命名源自于命令行参数（eg: -client 或者 -server）。JVM Server 模式与 client 模式启动，最主要的差别在于：-server 模式启动时，速度较慢，但是一旦运行起来后，性能将会有很大的提升。原因是：当虚拟机运行在-client 模式的时候，使用的是一个代号为 C1 的轻量级编译器，而-server 模式启动的虚拟机采用相对重量级代号为 C2 的编译器。C2 比 C1 编译器编译的相对彻底，服务起来之后，性能更高。 通过 java -version 命令行可以直接查看当前系统使用的是 client 还是 server 模式。 JVM内存模型： 按照JVM规范，JAVA虚拟机在运行时会管理以下的内存区域： 程序计数器：当前线程执行的字节码的行号指示器，线程私有 JAVA虚拟机栈：Java方法执行的内存模型，每个Java方法的执行对应着一个栈帧的进栈和出栈的操作。 本地方法栈：类似“ JAVA虚拟机栈 ”，但是为native方法的运行提供内存环境。 JAVA堆：对象内存分配的地方，内存垃圾回收的主要区域，所有线程共享。可分为新生代，老生代。 方法区：用于存储已经被JVM加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。Hotspot中的“永久代”。 注意：这里的永久代(PermanentSpace)针对jdk1.7之前的版本，JDK1.7常量已经放在Heap分区，JDK8中则完全移除了PermanentSpace，InternedStrings也被放到了MetaSpace（元空间）中 运行时常量池：方法区的一部分，存储常量信息，如各种字面量、符号引用等。 直接内存：并不是JVM运行时数据区的一部分， 可直接访问的内存， 比如NIO会用到这部分。 按照JVM规范，除了程序计数器不会抛出OOM外，其他各个内存区域都可能会抛出OOM。 判断对象存活状态根路径搜索算法(GC-Root-trancing)如果对象与GC-Root之间不可达，则认为该对象可回收解决了引用计数器方法不能回收两个循环引用但无外部引用的对象这一问题 三种GC算法： 标记-清除算法(Mark-sweep) （老年代）分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记对象。缺点：1）产生大量不连续的内存碎片2）标记和清除效率都不高 复制算法(Copying) （新生代）它将可用内存按照容量划分为大小相等的两块，每次只使用其中一块。当这一块的内存用完了，则就将还存活的对象复制到另一块上面，然后再把已经使用过的内存空间一次清理掉。使得每次都是对整个半区进行内存回收。 优点：1）不会出现内存碎片。2）只需移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。 缺点：1）将内存缩小为原来的一半。2）在对象存活率较高时会进行较多复制操作，效率较低。 商业虚拟机的分配担保机制：将内存分为一块较大的 eden 空间和两块较小的 survivor 空间，默认比例是 8:1:1，即每次新生代中可用内存空间为整个新生代容量的 90%，每次使用 eden 和其中一个 survivour。当回收时，将 eden 和 survivor 中还存活的对象一次性复制到另外一块 survivor 上，最后清理掉 eden 和刚才用过的 survivor，若另外一块 survivor 空间没有足够内存空间存放上次新生代收集下来的存活对象时，这些对象将直接通过分配担保机制进入老年代。 标记-整理算法(Mark-Compact) （老年代）标记过程和“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清除，而是让所有存活对象都向一端移动，然后直接清理掉端边界以外的内存。 七种收集器： Serial （复制算法） ParNew （复制算法） Parallel Scavenge （复制算法） 并行 CMS(Concurrent Mark Sweep ) （标记-清除） 并发 Serial Old(MSC) （标记-整理） Parallel Old （标记-整理）并行 G1 （分块 总体看是标记-整理 每块都是复制算法） 最常见的OOM情况有以下三种： java.lang.OutOfMemoryError: Java heap space ——&gt;java堆内存溢出，此种情况最常见，一般由于内存泄露或者堆的大小设置不当引起。对于内存泄露，需要通过内存监控软件查找程序中的泄露代码，而堆大小可以通过虚拟机参数-Xms,-Xmx等修改。 java.lang.OutOfMemoryError: PermGen space ——&gt;java永久代溢出，即方法区溢出了，一般出现于大量Class或者jsp页面，或者采用cglib等反射机制的情况，因为上述情况会产生大量的Class信息存储于方法区。此种情况可以通过更改方法区的大小来解决，使用类似-XX:PermSize=64m -XX:MaxPermSize=256m的形式修改。另外，过多的常量尤其是字符串也会导致方法区溢出。 java.lang.StackOverflowError ——&gt; 不会抛OOM error，但也是比较常见的Java内存溢出。JAVA虚拟机栈溢出，一般是由于程序中存在死循环或者深度递归调用造成的，栈大小设置太小也会出现此种溢出。可以通过虚拟机参数-Xss来设置栈的大小。 OOM分析: –heapdump 设置JVM参数-XX:+HeapDumpOnOutOfMemoryError，设定当发生OOM时自动dump出堆信息。不过该方法需要JDK5以上版本。 使用JDK自带的jmap命令。”jmap -dump:format=b,file=heap.bin “ 其中pid可以通过jps获取。 dump堆内存信息后，需要对dump出的文件进行分析，从而找到OOM的原因。常用的工具有： mat: eclipse memory analyzer, 基于eclipse RCP的内存分析工具。详细信息参见：http://www.eclipse.org/mat/， 推荐使用。 jhat：JDK自带的java heap analyze tool，可以将堆中的对象以html的形式显示出来，包括对象的数量，大小等等，并支持对象查询语言OQL，分析相关的应用后，可以通过http://localhost:7000 来访问分析结果。不推荐使用，因为在实际的排查过程中，一般是先在生产环境 dump出文件来，然后拉到自己的开发机器上分析，所以，不如采用高级的分析工具比如前面的mat来的高效。 Plumbr 如何减少GC出现的次数： 对象不用时显示置null。 少用System.gc()。 尽量少用静态变量。 尽量使用StringBuffer，而不用String累加字符串。 分散对象创建或删除的时间。 少用finalize函数。 如果需要使用经常用到的图片，可以使用软引用类型，它可以尽可能将图片保存在内存中，供程序调用，而不引起OOM。 能用基本类型就不用基本类型封装类。 增大-Xmx的值。 类加载的时机 遇到new、getstaic、putstatic或invokestatic这4条字节码指令时，如果类没有进行过初始化，则会触发初始化。 使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行过初始化，则会先触发其初始化。 当初始化一个类的时候，如果发现其父类还没进行过初始化，则需要触发其父类初始化。 当虚拟机启动时，用户需要指定一个要执行的主类，虚拟机会先初始化这个主类。 当使用jdk1.7动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果 REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则会先触发其初始化。 类加载器（ClassLoader）的双亲委派模型:类加载时，默认首先寻找父 类加载器（parent class loader）,如果没有找到就会选择BootStrap ClassLoader, 反射 java的反射机制主要是指程序可以访问，检测和修改它本身状态或行为的一种能力，并能根据自身行为的状态和结果，调整或修改应用所描述行为的状态和相关的语义。反射是java中一种强大的工具，能够使我们很方便的创建灵活的代码，这些代码可以再运行时装配，无需在组件之间进行源代码链接。但是反射使用不当会成本很高！ 从代码中可以看出，先检查 AccessibleObject的override属性是否为true（override属性默认为false）。AccessibleObject是Method,Field,Constructor的父类,可调用setAccessible方法改变，如果设置为true,则表示可以忽略访问权限的限制，直接调用。如果不是ture,则要进行访问权限检测。用Reflection的quickCheckMemberAccess方法先检查是不是public的，如果不是再用Reflection.getCallerClass()方法获得到调用这个方法的Class,然后做是否有权限访问的校验，校验之后缓存一次，以便下次如果还是这个类来调用就不用去做校验了，直接用上次的结果。 简而言之，通过反射，我们可以在运行时获得程序或程序集中每一个类型的成员和成员的信息。程序中一般的对象的类型都是在编译期就确定下来的，而 Java 反射机制可以动态地创建对象并调用其属性，这样的对象的类型在编译期是未知的。所以我们可以通过反射机制直接创建对象，即使这个对象的类型在编译期是未知的。 反射的核心是 JVM 在运行时才动态加载类或调用方法/访问属性，它不需要事先（写代码的时候或编译期）知道运行对象是谁。 Java 反射主要提供以下功能： 在运行时判断任意一个对象所属的类； 在运行时构造任意一个类的对象； 在运行时判断任意一个类所具有的成员变量和方法（通过反射甚至可以调用private方法）； 在运行时调用任意一个对象的方法 由于反射会额外消耗一定的系统资源，因此如果不需要动态地创建一个对象，那么就不需要用反射。 另外，反射调用方法时可以忽略权限检查，因此可能会破坏封装性而导致安全问题。 AOP (aspect-oriented programming 面向切面编程) 面向切面编程的思想里面，把功能分为核心业务功能，和周边功能． 业务代码:登录登出，增删改查， 周边代码:权限检查，日志管理，事务管理，性能检查(方法执行耗时) AOP能够将那些与业务无关，却为业务模块所共同调用的逻辑或责任（例如事务处理、日志管理、权限控制等）封装起来，便于减少系统的重复代码，降低模块间的耦合度，并有利于未来的可拓展性和可维护性。本质：代理模式 代理增强一般会用到Spring的动态代理库CGLib或者JDK自带的动态代理库，注意一个细节是如果被代理的对象没有抽象接口，则不能用JDK代理，而Spring AOP没有这个限制另一个细节是Spring AOP有一个@DeclareParents引介增强注解可以为Bean引入另一个Bean的方法 Spring Spring框架四大模块： Data:提供了一些数据相关的组件：包括JDBC、orm（对象关系映射）、事务操作、oxm（对象xml映射）、Jms（Java消息服务）。 WEB:扩展了Spring的Web功能。使其符合MVC的设计规范，最重要的是提供了Spring MVC的容器。 AOP:负责Spring的所有AOP（面向切面）的功能。(日志，事务) Core Container:核心容器，从核心俩字我们可以看出，这是Spring最重要的部分。主要的功能是实现了控制反转（IOC）与依赖注入（DI）、Bean配置、加载以及生命周期的管理。 Spring IOC控制反转，依赖注入Factory生成代理bean时机，依赖注入时机 注入方式： 构造器注入 setter注入 接口注入 Spring cloud了解Spring cloud之前需要先了解下什么是微服务 微服务（Micro Service）:微服务是一种架构风格，一个大型复杂软件应用由一个或多个微服务组成。系统中的各个微服务可被独立部署，各个微服务之间是松耦合的。每个微服务仅关注于完成一件任务并很好地完成该任务。在所有情况下，每个任务代表着一个小的业务能力。 微服务为什么会出现？ 大型整体式应用维护困难。 传统架构升级困难。 新的轻量级协议(RESTful)、容器化(Docker)的出现。 Spring Cloud是一套用于微服务的、简单易懂、易部署和易维护的分布式系统开发工具包。它利用Spring Boot的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，都可以用Spring Boot的开发风格做到一键启动和部署。 Spring Cloud如何实现微服务？ Eureka（注册中心）：负责所有微服务的管理。 Ribbon（服务发现）：主要负责客户端的负载均衡 Feign（接口伪装）：使微服务之间的调用像本地调用一样简单。 Hystrix（熔断处理）：在微服务出现问题时防止出现雪崩效应。 Zuul（代理机制）：安全认证、动态路由、流量管理、服务器负载均衡 Config（配置管理）：管理所有微服务的配置文件（GIT/SVN）。 DobboSQL善用 explain执行计划 事务事务属性（ACID） 原子性（Atomicity）：事务是一个原子操作单元。在当时原子是不可分割的最小元素，其对数据的修改，要么全部成功，要么全部都不成功。 一致性（Consistent）：事务开始到结束的时间段内，数据都必须保持一致状态。 隔离性（Isolation）：数据库系统提供一定的隔离机制，保证事务在不受外部并发操作影响的”独立”环境执行。 持久性（Durable）：事务完成后，它对于数据的修改是永久性的，即使出现系统故障也能够保持。 回滚日志（undo log）和重做日志（redo log）在数据库系统中，事务的原子性和持久性是由事务日志（transaction log）保证的，在实现时也就是上面提到的两种日志，前者用于对事务的影响进行撤销，后者在错误处理时对已经提交的事务进行重做，它们能保证两点： 发生错误或者需要回滚的事务能够成功回滚（原子性）；在事务提交后，数据没来得及写会磁盘就宕机时，在下次重新启动后能够成功恢复数据（持久性）；在数据库中，这两种日志经常都是一起工作的，我们可以将它们整体看做一条事务日志，其中包含了事务的 ID、修改的行元素以及修改前后的值。一条事务日志同时包含了修改前后的值，能够非常简单的进行回滚和重做两种操作， 事务常见问题 更新丢失（Lost Update）原因：当多个事务选择同一行操作，并且都是基于最初选定的值，由于每个事务都不知道其他事务的存在，就会发生更新覆盖的问题。类比github提交冲突。 脏读（Dirty Reads）原因：事务A读取了事务B已经修改但尚未提交的数据。若事务B回滚数据，事务A的数据存在不一致性的问题。 不可重复读（Non-Repeatable Reads）原因：事务A第一次读取最初数据，第二次读取事务B已经提交的修改或删除数据。导致两次读取数据不一致。不符合事务的隔离性。 幻读（Phantom Reads）原因：事务A根据相同条件第二次查询到事务B提交的新增数据，两次数据结果集不一致。不符合事务的隔离性。 幻读和脏读有点类似脏读是事务B里面修改了数据，幻读是事务B里面新增了数据。 隔离级别：MySQL默认的是可重复读的隔离级别 隔离级别 读数据一致性 脏读 不可重复读 幻读 未提交读(Read uncommitted) 最低级别 是 是 是 已提交读(Read committed) 语句级 否 是 是 可重复读(Repeatable read) 事务级 否 否 是 可序列化(Serializable) 最高级别，事务级 否 否 否 RAED UNCOMMITED：使用查询语句不会加锁，可能会读到未提交的行（Dirty Read）；READ COMMITED：只对记录加记录锁，而不会在记录之间加间隙锁，所以允许新的记录插入到被锁定记录的附近，所以再多次使用查询语句时，可能得到不同的结果（Non-Repeatable Read）；REPEATABLE READ：多次读取同一范围的数据会返回第一次查询的快照，不会返回不同的数据行，但是可能发生幻读（Phantom Read）；SERIALIZABLE：InnoDB 隐式地将全部的查询语句加上共享锁，解决了幻读的问题； 以上的所有的事务隔离级别都不允许脏写入（Dirty Write），也就是当前事务更新了另一个事务已经更新但是还未提交的数据，大部分的数据库中都使用了 READ COMMITED 作为默认的事务隔离级别，但是 MySQL 使用了 REPEATABLE READ 作为默认配置；从 RAED UNCOMMITED 到 SERIALIZABLE，随着事务隔离级别变得越来越严格，数据库对于并发执行事务的性能也逐渐下降。 行锁与表锁行锁行锁的劣势：开销大；加锁慢；会出现死锁行锁的优势：锁的粒度小，发生锁冲突的概率低；处理并发的能力强加锁的方式：自动加锁。对于UPDATE、DELETE和INSERT语句，InnoDB会自动给涉及数据集加排他锁；对于普通SELECT语句，InnoDB不会加任何锁；当然我们也可以显示的加锁：共享锁：’select 语句 + lock in share more’排他锁：’select 语句 + for update’ 间隙锁(GAP) (Next-Key锁) 锁住当前行的同时还会锁住相邻的行 排他锁 也称写锁，独占锁。当前写操作没有完成前，它会阻断其他写锁和读锁。 共享锁 也称读锁，多用于判断数据是否存在，多个读操作可以同时进行而不会互相影响。当如果事务对读锁进行修改操作，很可能会造成死锁。 表锁 共享读锁不会阻塞其他进程对同一表的读操作，但会阻塞对同一表的写操作。只有当读锁释放后，才能执行其他进程的写操作。在锁释放前不能取其他表。 独占写锁会阻塞其他进程对同一表的读和写操作，只有当写锁释放后，才会执行其他进程的读写操作。在锁释放前不能写其他表。 使用乐观锁更新的时候不加锁，当提交更新时需要判断数据是否已经被修改（AND number=#{number}），只有在 number等于上一次查询到的number时 才提交更新。有 CAS思想（Compare And Set）比较，没有冲突则修改 MySql两种常见引擎：InnoDB 和 MyISAM两者都使用B+Tree作为索引的数据结构，区别是InnoDB支持事务，而MyISAM不支持；InnoDB 和 MyISAM之间的区别：1&gt;.InnoDB支持事物，而MyISAM不支持事物 2&gt;.InnoDB支持行级锁，而MyISAM支持表级锁 3&gt;.InnoDB支持MVCC, 而MyISAM不支持 4&gt;.InnoDB支持外键，而MyISAM不支持 5&gt;.InnoDB不支持全文索引，而MyISAM支持。（X) MVCCMySql中的MVCC本质就是： 更新前建立undo log，根据各种策略读取时非阻塞就是MVCC 通过维护多个版本的数据，数据库可以允许事务在数据被其他事务更新时对旧版本的数据进行读取，很多数据库都对这一机制进行了实现；因为所有的读操作不再需要等待写锁的释放，所以能够显著地提升读的性能，MySQL 和 PostgreSQL 都对这一机制进行自己的实现，也就是 MVCC，虽然各自实现的方式有所不同，MySQL 就通过文章中提到的回滚日志实现了 MVCC，保证事务并行执行时能够不等待互斥锁的释放直接获取数据。 一般我们认为MVCC有下面几个特点： 每行数据都存在一个版本，每次数据更新时都更新该版本 修改时Copy出当前版本随意修改，个事务之间无干扰 保存时比较版本号，如果成功（commit），则覆盖原记录；失败则放弃copy（rollback） 就是每行都有版本号，保存时根据版本号决定是否成功，听起来含有乐观锁的味道。。。，而Innodb的实现方式是： 事务以排他锁的形式修改原始数据 把修改前的数据存放于undo log，通过回滚指针与主数据关联 修改成功（commit）啥都不做，失败则恢复undo log中的数据（rollback） Innodb的实现真算不上MVCC，因为并没有实现核心的多版本共存，undo log中的内容只是串行化的结果，记录了多个事务的过程，不属于多版本共存。但理想的MVCC是难以实现的，当事务仅修改一行记录使用理想的MVCC模式是没有问题的，可以通过比较版本号进行回滚；但当事务影响到多行数据时，理想的MVCC据无能为力了。 聚集索引和非聚集索引聚集索引表记录的排列顺序与索引的排列顺序一致 聚集索引中叶子节点保存的就是数据本身，key是主键，而非聚集索引中叶子节点储存的是主键，还需要通过主键查找数据 优点是查询速度快，因为一旦具有第一个索引值的纪录被找到，具有连续索引值的记录也一定物理的紧跟其后。缺点是对表进行修改速度较慢，这是为了保持表中的记录的物理顺序与索引的顺序一致，而把记录插入到数据页的相应位置，必须在数据页中进行数据重排， 降低了执行速度。建议使用聚集索引的场合为： 此列包含有限数目的不同值； 查询的结果返回一个区间的值； 查询的结果返回某值相同的大量结果集。 范围查询时必须要聚集索引 非聚集索引指定了表中记录的逻辑顺序，但记录的物理顺序和索引的顺序不一致，聚集索引和非聚集索引都采用了B+树的结构，但非聚集索引的叶子层并不与实际的数据页相重叠，而采用叶子层包含一个指向表中的记录在数据页中的指针的方式。非聚集索引比聚集索引层次多，添加记录不会引起数据顺序的重组。建议使用非聚集索引的场合为： 此列包含了大量数目不同的值； 查询的结束返回的是少量的结果集； order by 子句中使用了该列。 hash索引hash索引，相比较于B树而言，不需要从根节点到叶子节点的遍历，可以一次定位到位置，查询效率更高，但缺点也很明显 仅能满足”=”,”IN”和”&lt;=&gt;”查询，不能使用范围查询 因为是通过hash值进行计算，所以只能精确查询，hash值是没什么规律的，不能保证顺序和原来一致，所以范围查询不行 无法进行排序 原因同上 不支持部分索引 hash值的计算，是根据完整的几个索引列计算，如果少了其中一个乃至几个，这个hash值就没法计算了 hash碰撞 mysql保证事务的隔离性主要通过Lock(锁)和MVCC(multiple version concurrent control 多版本并发控制) 总结 InnoDB 支持表锁和行锁，使用索引作为检索条件修改数据时采用行锁，否则采用表锁。 InnoDB 自动给修改操作加锁，给查询操作不自动加锁 行锁可能因为未使用索引而升级为表锁，所以除了检查索引是否创建的同时，也需要通过explain执行计划查询索引是否被实际使用。 行锁相对于表锁来说，优势在于高并发场景下表现更突出，毕竟锁的粒度小。 当表的大部分数据需要被修改，或者是多表复杂关联查询时，建议使用表锁优于行锁。 为了保证数据的一致完整性，任何一个数据库都存在锁定机制。锁定机制的优劣直接影响到一个数据库的并发处理能力和性能。 多线程两种重要的锁：synchronized lock 类别 synchronized Lock 存在层次 Java的关键字，在jvm层面上 是一个类 锁的释放 1、以获取锁的线程执行完同步代码，释放锁 2、线程执行发生异常，jvm会让线程释放锁 在finally中必须释放锁，不然容易造成线程死锁 锁的获取 假设A线程获得锁，B线程等待。如果A线程阻塞，B线程会一直等待 分情况而定，Lock有多个锁获取的方式，具体下面会说道，大致就是可以尝试获得锁，线程可以不用一直等待 锁状态 无法判断 可以判断 锁类型 可重入 不可中断 非公平 可重入 可判断 可公平（两者皆可） 性能 少量同步 大量同步 synchronized关键字可以作为函数的修饰符，也可作为函数内的语句，也就是平时说的同步方法和同步语句块。如果 再细的分类，synchronized可作用于instance变量、object reference（对象引用）、static函数和class literals(类名称字面常量)身上。 无论synchronized关键字加在方法上还是对象上，它取得的锁都是对象，而不是把一段代码或函数当作锁――而且同步方法很可能还会被其他线程的对象访问。 每个对象只有一个锁（lock）与之相关联。 volatile 轻量级，只保证修改同步和可见性，不保证线程安全 atomic 乐观锁 AtomicInteger 通过CAS（Compare And Set）操作实现线程安全的自增。CAS 可能会带来ABA问题 LongAdder 思路类似于ConcurrentHashMap，Cell数组分块加锁 AQS框架（AbstractQueuedSynchronizer的简写，中文名应该叫抽象队列同步器） IO模型BIO，NIO，AIO]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>面试</tag>
        <tag>Interview</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试准备大纲]]></title>
    <url>%2FJava%2FPrepare-For-Java-Interview.html</url>
    <content type="text"><![CDATA[数据结构 集合 数组 String 基本数据类型与对应实例对象(装箱和拆箱) java基础 各种修饰符 关键字 反射 AOP(注解) 代理 泛型 多线程 JVM 常用设计模式单例模式，工厂模式，观察者模式, 装饰器模式，代理模式，职责链模式， 五大io模型 常用框架或中间件 Spring(IOC) Spring Boot. Spring mybatis. Shiro Zookeeper. rabbitmq. kafka. elasticsearch. RPC(Dobbo) Spring cloud. 数据库相关 mysql, postgresql, DynamoDB, MongoDB, Redis, Memcached]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>面试</tag>
        <tag>Interview</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot整合Elastic Job简单实践Demo]]></title>
    <url>%2FJava%2Felastic-job-with-spring-boot-demo.html</url>
    <content type="text"><![CDATA[简介 Elastic-Job是一个分布式调度解决方案，由两个相互独立的子项目Elastic-Job-Lite和Elastic-Job-Cloud组成。Elastic-Job-Lite定位为轻量级无中心化解决方案，使用jar包的形式提供最轻量级的分布式任务的协调服务，外部依赖仅Zookeeper。 你可以在官方文档页面了解更多信息．此处就不详细介绍了． 关于ZookeeperElastic Job依赖Zookeeper作为调度中心协调任务的分片和调度以支持分布式，所以我们首先需要搭建一个Zookeeper环境.由于这不是本文的重点，此处就不详细介绍了．为了体现其高可用和高效率的特点，一般需要三个Zookeeper节点组成集群．这里由于只是验证性的Demo，因此我是在本地搭建的单节点Zookeeper注册中心．简述一下Linux下的安装过程： 下载Zookeeper的安装包，然后解压到/opt目录．这里下载的是 3.4.10 版本． 1tar zxvf zookeeper-3.4.10.tar.gz -C /opt 在/opt目录新建zk_data和zk_logs 两个目录，并赋777权限12mkdir zk_data zk_logschmod 777 zk_data zk_logs 在Zookeeper的解压目录中/conf目录下新建zoo.cfg文件．123456789101112131415161718192021222324252627282930# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial# synchronization phase can takeinitLimit=10# The number of ticks that can pass between# sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just# example sakes.dataDir=/opt/zk_datadataLogDir=/opt/zk_logs# the port at which the clients will connectclientPort=2181server.1=127.0.0.1:2888:3888# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the# administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to "0" to disable auto purge feature#autopurge.purgeInterval=1 启动Zookeeper服务,在/opt/zookeeper-3.4.10/bin/目录下执行1zkServer.sh start 查看状态1zkServer.sh status 你还可以：配置全局命令编辑.bashrc(如果你使用zsh那么编辑.zshrc)添加一下配置以支持全局命令：.bashrc和.zshrc一般在home文件夹下12export ZOOKEEPER_HOME=/opt/zookeeper-3.4.10export PATH=$ZOOKEEPER_HOME/bin:$PATH 以上，单机Zookeeper就配置好了． 添加Maven 依赖123456789101112131415161718192021222324252627282930313233&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;version&gt;1.4.2.RELEASE&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!-- 引入elastic-job-lite核心模块 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.dangdang&lt;/groupId&gt; &lt;artifactId&gt;elastic-job-lite-core&lt;/artifactId&gt; &lt;version&gt;2.0.5&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 使用springframework自定义命名空间时引入 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.dangdang&lt;/groupId&gt; &lt;artifactId&gt;elastic-job-lite-spring&lt;/artifactId&gt; &lt;version&gt;2.0.5&lt;/version&gt;&lt;/dependency&gt; 编辑配置文件application.properties123456789101112131415161718#elastic jobzookeeper.serviceLists=127.0.0.1:2181zookeeper.namespace=anduin-elastic-job-testzookeeper.baseSleepTimeMilliseconds=5000zookeeper.maxSleepTimeMilliseconds=5000zookeeper.maxRetries=3#定时任务simpleJob.mySimpleJob.name=mySimpleJob# Seconds Minutes Hours Day-of-Month Month Day-of-Week Year (可选字段)simpleJob.mySimpleJob.cron=*/10 * * * * ?simpleJob.mySimpleJob.shardingTotalCount=1demo.demoJob.name=demoJobdemo.demoJob.cron=*/5 * * * * ?demo.demoJob.shardingTotalCount=1 新建ZookeeperConfig配置类以Spring Boot注解的方式配置Zookeeper，12345678910111213141516171819202122232425262728293031323334353637383940414243package com.zobgo.job.javaconfig;import com.dangdang.ddframe.job.reg.zookeeper.ZookeeperConfiguration;import com.dangdang.ddframe.job.reg.zookeeper.ZookeeperRegistryCenter;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * Created by zongbo.zhang on 8/15/18.*/@Configurationpublic class ZookeeperConfig &#123; @Value("$&#123;zookeeper.serviceLists&#125;") private String serviceLists; @Value("$&#123;zookeeper.namespace&#125;") private String nameSpace; @Value("$&#123;zookeeper.baseSleepTimeMilliseconds&#125;") private int baseSleepTimeMilliseconds; @Value("$&#123;zookeeper.maxSleepTimeMilliseconds&#125;") private int maxSleepTimeMilliseconds; @Value("$&#123;zookeeper.maxRetries&#125;") private int maxRetries; /** * zookeeper 配置 * @return */ @Bean(initMethod = "init") public ZookeeperRegistryCenter zookeeperRegistryCenter()&#123; ZookeeperConfiguration configuration = new ZookeeperConfiguration(serviceLists,nameSpace); configuration.setBaseSleepTimeMilliseconds(baseSleepTimeMilliseconds); configuration.setMaxSleepTimeMilliseconds(maxSleepTimeMilliseconds); configuration.setMaxRetries(maxRetries); return new ZookeeperRegistryCenter(configuration); &#125;&#125; 新建一个DemoJob类．这个一个SimpleJob的实现类，具体的Job逻辑在这里实现，这个DemoJob的工作就是打印一条日志1234567891011121314151617181920212223242526272829package com.zobgo.job.demo;import com.dangdang.ddframe.job.api.ShardingContext;import com.dangdang.ddframe.job.api.simple.SimpleJob;import org.springframework.stereotype.Component;import lombok.extern.slf4j.Slf4j;/** * Created by zongbo.zhang on 8/23/18. */@Slf4j@Componentpublic class DemoJob implements SimpleJob &#123; @Override public void execute(ShardingContext shardingContext) &#123; log.info("&lt;====Demo Job Begin====&gt;"); log.info(String.format("------Thread ID: %s, 任务总片数: %s, 当前分片项: %s", Thread.currentThread().getId(), shardingContext.getShardingTotalCount(), shardingContext.getShardingItem())); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; log.info("&lt;====Demo Job End====&gt;"); &#125;&#125; 新建DemoConfig配置类DemoConfig是对DemoJob的配置，包括注册中心，Cron表达式，分片数，任务监听器等123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package com.zobgo.job.javaconfig;import com.dangdang.ddframe.job.config.JobCoreConfiguration;import com.dangdang.ddframe.job.config.simple.SimpleJobConfiguration;import com.dangdang.ddframe.job.lite.api.JobScheduler;import com.dangdang.ddframe.job.lite.config.LiteJobConfiguration;import com.dangdang.ddframe.job.lite.spring.api.SpringJobScheduler;import com.dangdang.ddframe.job.reg.zookeeper.ZookeeperRegistryCenter;import com.zobgo.job.demo.DemoJob;import com.zobgo.job.listener.MyElasticJobListener;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import javax.annotation.Resource;/** * Created by zongbo.zhang on 8/23/18. */@Configurationpublic class DemoConfig &#123; @Resource private ZookeeperRegistryCenter registryCenter; @Value("$&#123;demo.demoJob.name&#125;") private String demoJobName; @Value("$&#123;demo.demoJob.cron&#125;") private String demoJobCron; @Value("$&#123;demo.demoJob.shardingTotalCount&#125;") private int demoJobShardingTotalCount; @Bean public DemoJob demoJob()&#123; return new DemoJob(); &#125; @Bean(initMethod = "init") public JobScheduler demoJobScheduler(final DemoJob demoJob)&#123; MyElasticJobListener elasticJobListener = new MyElasticJobListener(); return new SpringJobScheduler(demoJob,registryCenter,liteJobConfiguration(),elasticJobListener); &#125; private LiteJobConfiguration liteJobConfiguration()&#123; return LiteJobConfiguration.newBuilder( new SimpleJobConfiguration( JobCoreConfiguration.newBuilder(demoJobName,demoJobCron,demoJobShardingTotalCount).build() ,DemoJob.class.getCanonicalName() )).overwrite(true).build(); &#125;&#125; 新建MyElasticJobListener Job监听器，可以在Job开始和结束时进行一些操作，比如Job结束时发送一封邮件，这里的监听器的作用是统计Job的执行耗时123456789101112131415161718192021222324252627282930313233343536373839package com.zobgo.job.listener;import com.dangdang.ddframe.job.executor.ShardingContexts;import com.dangdang.ddframe.job.lite.api.listener.ElasticJobListener;import com.zogbo.common.utils.TimeUtil;import java.util.Date;import lombok.extern.slf4j.Slf4j;/** * Created by zongbo.zhang on 8/17/18. * * 任务总监听器 */@Slf4jpublic class MyElasticJobListener implements ElasticJobListener&#123; private long beginTime = 0; @Override public void beforeJobExecuted(ShardingContexts shardingContexts) &#123; beginTime = System.currentTimeMillis(); log.info("===&gt;&#123;&#125; JOB BEGIN TIME: &#123;&#125; &lt;===",shardingContexts.getJobName(), TimeUtil.mill2Time(beginTime)); &#125; @Override public void afterJobExecuted(ShardingContexts shardingContexts) &#123; long endTime = System.currentTimeMillis(); log.info("===&gt;&#123;&#125; JOB END TIME: &#123;&#125;,TOTAL CAST: &#123;&#125; &lt;===",shardingContexts.getJobName(), TimeUtil.mill2Time(endTime), endTime - beginTime); &#125; public static void main(String[] args) &#123; System.out.println(TimeUtil.mill2Time(System.currentTimeMillis())); &#125;&#125; 对了，这里用到了我在Util中实现的一个TimeUtil.mill2Time方法，就是一个很简单的把Unix TimeStamp时间格式化为年月日时间的类 1234public static String mill2Time(long mill)&#123; SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss SSS"); return sdf.format(mill); &#125; 新建启动类AnduinJobApplicationSpring Boot的启动类JobApplication 123456789101112131415161718192021package com.zobgo;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.ComponentScan;import lombok.extern.slf4j.Slf4j;/** * Created by zongbo.zhang on 8/16/18. */@SpringBootApplication@Slf4j@ComponentScan(basePackages = &#123;"com.zobgo"&#125;)public class AnduinJobApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(AnduinJobApplication.class,args); &#125;&#125; 项目目录结构： 项目中用到了@Slf4j 如果日志接口导致不能运行，则把log.info换成System.out.println();成功运行，效果如下: 简单实践假设有这样一个场景： 有一张用户评论表comment，table comment中有一个comment_status字段标识该条评论的删除状态：0 - 删除 | 1 - 正常，由于某种原因，一直有评论需要从删除状态恢复到正常状态(假设有这种奇怪的需求)．0 -&gt; 1，这时就需要一个定时任务，每隔一定时间扫描一次table,然后找出所有的需要修改的评论，更新其状态为1，这时就可以考虑用Elastic Job来实现．comment表如图： 轮询修改数据库的定时任务MySimpleJob12345678910111213141516171819202122232425262728293031323334353637package com.zobgo.job.simple;import com.zobgo.business.comment.model.Comment;import com.zobgo.business.comment.service.api.CommentService;import com.dangdang.ddframe.job.api.ShardingContext;import com.dangdang.ddframe.job.api.simple.SimpleJob;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.Lazy;import org.springframework.stereotype.Component;import java.util.ArrayList;import java.util.List;import lombok.extern.slf4j.Slf4j;/** * Created by zongbo.zhang on 8/15/18. */@Slf4j@Componentpublic class MySimpleJob implements SimpleJob &#123; @Autowired @Lazy CommentService commentService; @Override public void execute(ShardingContext shardingContext) &#123; List&lt;Comment&gt; comments = commentService.getCommentByStatus(0); log.info("待更新条数： &#123;&#125;",comments.size()); List&lt;Long&gt; commentIds = new ArrayList&lt;&gt;(); comments.forEach(comment -&gt; commentIds.add(comment.getCommentId())); commentService.updateCommentByCommentIds(Byte.valueOf("1"),commentIds); log.info("更新了: &#123;&#125;条记录", comments.size()); &#125;&#125; 当然，和上面的Demo一样，还需要一个定时任务的配置类 轮询修改数据库的定时任务的配置类MySimpleConfig12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package com.zobgo.job.javaconfig;import com.dangdang.ddframe.job.config.JobCoreConfiguration;import com.dangdang.ddframe.job.config.simple.SimpleJobConfiguration;import com.dangdang.ddframe.job.lite.api.JobScheduler;import com.dangdang.ddframe.job.lite.config.LiteJobConfiguration;import com.dangdang.ddframe.job.lite.spring.api.SpringJobScheduler;import com.dangdang.ddframe.job.reg.zookeeper.ZookeeperRegistryCenter;import com.zobgo.job.listener.MyElasticJobListener;import com.zobgo.job.simple.MySimpleJob;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import javax.annotation.Resource;/** * Created by zongbo.zhang on 8/16/18. */@Configurationpublic class MySimpleConfig &#123; @Resource private ZookeeperRegistryCenter registryCenter; @Value("$&#123;simpleJob.mySimpleJob.name&#125;") private String mySimpleJobName; @Value("$&#123;simpleJob.mySimpleJob.cron&#125;") private String mySimpleJobCron; @Value("$&#123;simpleJob.mySimpleJob.shardingTotalCount&#125;") private int mySimpleJobShardingTotalCount; @Bean public MySimpleJob mySimpleJob()&#123; return new MySimpleJob(); &#125; @Bean(initMethod = "init") public JobScheduler mySimpleJobScheduler(final MySimpleJob mySimpleJob)&#123; MyElasticJobListener elasticJobListener = new MyElasticJobListener(); return new SpringJobScheduler(mySimpleJob,registryCenter, liteJobConfiguration(), elasticJobListener); &#125; private LiteJobConfiguration liteJobConfiguration()&#123; //定义Lite作业根配置 return LiteJobConfiguration.newBuilder(new SimpleJobConfiguration( JobCoreConfiguration.newBuilder(mySimpleJobName,mySimpleJobCron,mySimpleJobShardingTotalCount).build(), MySimpleJob.class.getCanonicalName() )).overwrite(true).build(); &#125;&#125; 至于Mybatis相关的Dao操作，和commentService中对comment具体的筛选与操作逻辑，由于不是本文重点，此处就不贴代码了．具体的项目源码已上传到Github，可以前往查看． 运行结果]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Elastic Job</tag>
        <tag>Zookeeper</tag>
        <tag>定时任务</tag>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Excel中财务函数PV,PMT公式的java实现]]></title>
    <url>%2FJava%2Fpv-pmt-expression-in-excel-java-code.html</url>
    <content type="text"><![CDATA[PV 是一个财务函数，用于根据固定利率计算贷款或投资的现值。 可以将 PV 与定期付款、固定付款（如按揭或其他贷款）或投资目标的未来值结合使用。 语法PV(rate, nper, pmt, [fv], [type]) 参数PV 函数语法具有下列参数： Rate 必需。 各期利率。 例如，如果您获得年利率为 10% 的汽车贷款，并且每月还款一次，则每月的利率为 10%/12（即 0.83%）。 您需要在公式中输入 10%/12（即 0.83%）或 0.0083 作为利率。 Nper 必需。 年金的付款总期数。 例如，如果您获得为期四年的汽车贷款，每月还款一次，则贷款期数为 4*12（即 48）期。 您需要在公式中输入 48 作为 nper。 Pmt 必需。 每期的付款金额，在年金周期内不能更改。 通常，pmt 包括本金和利息，但不含其他费用或税金。 例如，对于金额为 ￥100,000、利率为 12% 的四年期汽车贷款，每月付款为 ￥2633.30。 您需要在公式中输入 -2633.30 作为 pmt。 如果省略 pmt，则必须包括 fv 参数。 fv 可选。 未来值，或在最后一次付款后希望得到的现金余额。 如果省略 fv，则假定其值为 0（例如，贷款的未来值是 0）。 例如，如果要在 18 年中为支付某个特殊项目而储蓄 ￥500,000，则 ￥500,000 就是未来值。 然后，您可以对利率进行保守的猜测，并确定每月必须储蓄的金额。 如果省略 fv，则必须包括 pmt 参数。 类型 可选。 数字 0 或 1，用以指定各期的付款时间是在期初还是期末。 公式Microsoft Excel 根据其他参数来求解某个金融参数。 如果 rate 不为 0，则： 如果 rate 为 0，则： (pmt * nper) + pv + fv = 0 文档 以上是Office 的 support 文档对PV计算的部分介绍,详细可以看看Office文档 java代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package com.insurance.common.utill;import java.math.BigDecimal;/** * Created by zhangzb on 2018/06/26. */public class PMTUtil &#123; public static double pmtRoundDown(double monthRate,int periods,double amount)&#123; double var = Math.pow(1 + monthRate,periods); double pmtAmount = amount * (monthRate * var) / (var - 1); return new BigDecimal(pmtAmount).setScale(2, BigDecimal.ROUND_DOWN).doubleValue(); &#125; public static double pmt(double monthRate,int periods,double amount,int percise)&#123; double var = Math.pow(1 + monthRate,periods); double pmtAmount = amount * (monthRate * var) / (var - 1); return new BigDecimal(pmtAmount).setScale(percise, BigDecimal.ROUND_HALF_UP).doubleValue(); &#125; //参考 https://support.office.com/zh-CN/article/PV-%E5%87%BD%E6%95%B0-23879D31-0E02-4321-BE01-DA16E8168CBD public static double pv(double monthRate,int periods,double peridsAmount)&#123; /** * 如果年化收益率为零，monthRate作分母会出现NaN错误，需要对月利率为零进行特殊处理 */ if (monthRate == 0)&#123; return periods * peridsAmount; &#125; double var = Math.pow(1 + monthRate,-periods); double pvAmount = (peridsAmount - peridsAmount * var) / monthRate; return new BigDecimal(pvAmount).setScale(2, BigDecimal.ROUND_HALF_UP).doubleValue(); &#125; public static void main(String[]args)&#123; System.out.println(pmt(0.115/12,12,10000,2)); System.out.println(PMTUtil.pv(0.08 / 12,5,662.12)); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>pv</tag>
        <tag>pmt</tag>
        <tag>excel</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux解决unzip中文乱码]]></title>
    <url>%2FLinux%2Flinux-chinese-unzip-Garbled.html</url>
    <content type="text"><![CDATA[linux解压神器：unar 用过linux的同学可能多多少少接触过linux下文档的压缩归档，通常来说我们最喜欢的还是用tar命令进行文件的归档。可有些时候，我们也不得不面对windows下常用压缩格式.zip文档。这时候同学们最先想到的肯定就是linux自带的unzip，使用命令unzip files.zip解压.zip文档一气呵成，合情合理。unzip命令在大多数情况下也不会让我们失望。解压过程优雅迅捷。可是随着我们继续使用unzip，我们会发现一个unzip致命的缺陷：当.zip包中有中文命名的文件时，解压出来的文件名会乱码。效果如图： 网上有人给出了原因： 原因是unzip试图将zip文件中用 oem(ibm-dos) codepage 编码的文件名转换成自己的内部编码。可惜unzip只能转换极少数几种codepage，中文的 cp936 不在其列。 甚至还给出了解决方案： 修改unzip的源码：在unzip.cpp源文件的ZRESULT TUnzip::Get方法。 重新编译unzip，在编译时指定参数：make -DExt_ASCII_TO_Native。 解压时指定参数：类似与这样unzip -O CP936 xxx.zip (GBK, GB18030也可以)。 以上方法有些过于复杂，有些实测没有效果。这里不予推荐。这里推荐的是：12sudo apt install unarunar xxx.zip 使用unar后，解压中文就不会出现乱码啦，效果如图：]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>乱码</tag>
        <tag>Garbled</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客进阶--SEO优化]]></title>
    <url>%2FHexo%2Fhexo-search-engine-optimization.html</url>
    <content type="text"><![CDATA[搜索引擎优化（英语：search engine optimization，缩写为SEO），是一种通过了解搜索引擎的运作规则来调整网站，以及提高目的网站在有关搜索引擎内排名的方式。由于不少研究发现，搜索引擎的用户往往只会留意搜索结果最前面的几个条目，所以不少网站都希望通过各种形式来影响搜索引擎的排序，让自己的网站可以有优秀的搜索排名。当中尤以各种依靠广告维生的网站为甚。 优化你的urlseo搜索引擎优化认为，网站的最佳结构是用户从首页点击三次就可以到达任何一个页面，但是我们使用hexo编译的站点打开文章的url是：sitename/year/mounth/day/title四层的结构，这样的url结构很不利于seo，爬虫就会经常爬不到我们的文章，于是，我们可以将url直接改成sitename/title的形式，并且title最好是用英文，在站点配置文件下修改permalink如下： 1234url: https://www.zobgo.comroot: /permalink: :title.htmlpermalink_defaults: 注意：修改后文章的阅读量和评论会被清空，原因在于leanCloud的文章评论和阅读量是根据文章title和path记录的，之前文章阅读量和文章评论还绑定在旧的路径下．解决方法是打开leancloud，修改对应文章的路径 修改前路径：1/2018/05/17/hello-world/ 修改后路径：1/hello-world/ 这样评论和访问量就能正常显示了 添加站点地图sitemap.xml 安装sitemap站点地图自动生成插件 12$ npm install hexo-generator-sitemap --save$ npm install hexo-generator-baidu-sitemap --save 在主题配置文件中添加一下配置 12345sitemap: path: sitemap.xmlbaidusitemap: path: baidusitemap.xml 然后在站点配置文件中修改url为你的域名 1234# URL## If your site is put in a subdirectory, set url as &apos;http://yoursite.com/child&apos; and root as &apos;/child/&apos;url: https://zobgo.comroot: / 配置完成后，1$ hexo g 会在your-hexo-site\public 中生成sitemap.xml 和 baidusitemap.xml;其中sitemap.xml是一会要提交给google的，baidusitemap.xml当然就是提交给Baidu的了； 在your-hexo-site/source中新建文件robots.txt,内容如下： 请把其中我的域名换成你自己的 123456789101112131415User-agent: *Allow: /Allow: /archives/Allow: /categories/Allow: /tags/Disallow: /vendors/Disallow: /js/Disallow: /css/Disallow: /fonts/Disallow: /vendors/Disallow: /fancybox/Sitemap: https://zobgo.com/sitemap.xmlSitemap: https://zobgo.com/baidusitemap.xml 给非友情链接的出站链接添加 “nofollow” 标签参考这篇博文nofollow的目的是防止搜索引擎spider在爬取我们的站点时，从外链出逃到别的站点，这对我们的站点是不利的。所以我们要对友情链接等外链进行标记，禁止spider出逃。 登录google webmaster 并验证你的站点你有两种比较常用的方式验证你的站点： 上传HTML以验证 上传HTML，顾名思义，就是往你的站点根目录上传一个谷歌提供的html网页，以验证你是站点的所有者，操作很简单，注意顺序： 下载HTML验证文件 先hexo g生成一次，然后将文件拷贝到站点目录的source目录下 hexo d发布你的站点 访问验证文件（ 我的是 https://www.zobgo.com/google55174e28c4588446.html 已删除换用标记验证）确认上传成功，回到google search console完成验证。 这个方法有两个需要注意的地方:第一，文件必须放在站点的source目录下，对应站点的根路径。第二，要在hexo g生成之后拷贝文件，拷贝之后不能再执行hexo g，原因是hexo g时会对html文件进行样式的格式化，这样google webmaster无法验证，如果你访问验证网页时发现此页面有hexo主题的样式，那你将会验证失败 HTML标记验证 此方法hexo-theme-next已集成，推荐此方法。 首先获取 google site verification code，登录 Google Webmaster Tools，导航到验证方法，并选择 HTML Tag。将会获取到一段代码：&lt;meta name=&quot;google-site-verification&quot; content=&quot;XXXXXXXXXXXXXXXXXXXXXXX&quot; /&gt;将 content 里面的 XXXXXXXXXXXXXXXXXXXXXXX 复制出来。如下图： 修改站点配置文件_config.yml，新增字段 google_site_verification：1google_site_verification: XXXXXXXXXXXXXXXXXXXXXXX 提交你的sitemap.xml登录google webmaster，在对应位置提交sitemap 如图所示： 测试提交robots.txt提交之前先点击测试按钮，已允许之后方可提交，我已经提交过了，看下图 接下来就可以静静等待google索引我们的网站了，你也可以手动 提交索引请求： Google 抓取方式抓取–google抓取工具 输入url，选择桌面或者移动设备，开始抓取出现完成，部分完成，已重定向这三种结果时，就可以提交请求编入索引了 通过SEO优化，在谷歌搜索文章标题，我们的文章排在搜索结果的第一位：]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>SEO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo-next接入评论和搜索服务]]></title>
    <url>%2FHexo%2Fhexo-next-add-comment-and-search.html</url>
    <content type="text"><![CDATA[添加阅读量展示：使用LeanCloud hexo-next 6.0 集成了leancloud_visitors firestore busuanzi_count 三种统计插件，这里我们选择leanCloud在完成注册LeanCloud帐号并验证邮箱之后，登录我们的LeanCloud帐号，进行简单的配置之后拿到AppID以及AppKey这两个参数就可以可正常使用文章阅读量统计的功能了。 注册LeanCloud：完成了注册和激活邮箱，接下来我们需要进入控制台创建一个应用 创建应用这里我已经创建过一个test应用（你可以随意起名），直接点进去 建立class:点击控制台的存储标签，我们需要一个名为Counter的class，注意这里不要自定class的名字，必须为Counter 绑定AppID和AppKey:打开控制台的设置标签栏，应用Key查看我们的应用Key复制AppID以及AppKey并在NexT主题的_config.yml文件中我们相应的位置填入即可，正确配置之后文件内容像这个样子:1234leancloud_visitors: enable: true app_id: dxDMdMpg9PkOb6M9tTxy7CNS-gzGzoHsz app_key: MExhCaDhpuIdy9kLiTVLFoz3 这个时候重新生成部署Hexo博客，应该就可以正常使用文章阅读量统计的功能了。需要特别说明的是：记录文章访问量的唯一标识符是文章的发布日期以及文章的标题，因此请确保这两个数值组合的唯一性，如果你更改了这两个数值，会造成文章阅读数值的清零重计。最后，一定要在Leancloud -&gt; 设置 -&gt; 安全中心 -&gt; Web 安全域名 把你的域名加进去，防止你的LeanCloud应用被恶意利用。 添加评论展示：使用ValineValine的简介是: 一款快速、简洁且高效的无后端评论系统。 你也可以使用 多说 畅言 网易云跟帖 来比力 hypercomments Gitment disqus 这里我简单总结一下上面这些第三方评论服务的优缺点：多说，网易云跟帖已经先后在2017年3月，7月停止服务。搜狐畅言需要备案，disqus被墙，gitment仅支持github用户。来比力是韩国的，国内有时会不稳定。hypercomments在官网体验时感觉不错，但是貌似收费，没仔细研究，也可能是我没发现免费入口。valine的界面和Next主题很搭，国内访问速度很快，唯一的缺点就是评论不能添加图片(经评论提醒，是可以评论图片的) valine 也是基于LeanCloud的免费云服务进行的开发。跟上面的添加阅读量统计很类似，如果你已经接入过LeanCloud的阅读量统计，那么接下来就很简单了 让我们三步完成评论服务的接入：创建Comment Class：让我们回到LeanCloud在我们刚才建的test应用中新建一个名叫 Comment 的Class，注意，这个Class也不要自定名称，只能使用Comment修改NexT主题的_config.yml文件：12345678910valine: enable: true appid: dxDMdMpg9PkOb6M9tTxy7CNS-gzGzoHsz appkey: MExhCaDhpuIdy9kLiTVLFoz3 notify: false # 邮件通知 verify: false # Verification code placeholder: just go go #输入框提示语 avatar: wavatar # 头像风格 guest_info: nick,mail # 昵称，邮箱 pageSize: 10 # 每页展示条数 接入Valine评论完成效果如下： 如果还有什么不懂的，可以去看看Valine官方文档 添加站内搜索：使用LocalSearch安装hexo-generator-searchdb plugin进入到你的站点根目录，在此处开始安装1$ npm install hexo-generator-searchdb --save 修改站点配置文件_config.yml在站点配置文件任意位置添加以下配置：12345search: path: search.xml field: post format: html limit: 10000 修改主题配置文件_config.yml找到主题配置文件的local_search项，将其更改为：1234567local_search: enable: true # if auto, trigger search by changing input # if manual, trigger search by pressing enter key or search button trigger: auto # show top n results per article, show all results by setting to -1 top_n_per_article: 1 大功告成，效果如下：]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>commnet</tag>
        <tag>search</tag>
        <tag>评论</tag>
        <tag>搜索</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[云南移动app加密]]></title>
    <url>%2FJava%2Fyun-nan-china-mobile-app-encrypt.html</url>
    <content type="text"><![CDATA[登录需要用到的加密字段 Fields encrypt mode password des cbc jsonParam Base64 md5sign Md5 密码加密123password = EncryptGZipUtils.encode(EncryptGZipUtils.desEncode(secret, password.getBytes("UTF-8"))); jsonParam加密123456String data = "[&#123;\"dynamicURI\":\"/login\",\"dynamicParameter\":&#123;\"method\":\"ln\",\"m\":\""+ mobile +"\",\"p\":\""+ password + "\",\"deviceCode\":\"\"&#125;,\"dynamicDataNodeName\":\"pwdLogin_node\"&#125;]";String jsonParam = Base64.encode(data.getBytes("GBK")); 请求体中的md5sign123final String MD5_KEY = "11100android!@#";String Md5Sign = Md5Util.toMd5(MD5_KEY + deviceId + jsonParam); 登录密码加密util1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283package com.zhangzb.utils;import com.alibaba.fastjson.JSON;import com.alibaba.fastjson.JSONObject;import javax.crypto.Cipher;import javax.crypto.spec.IvParameterSpec;import javax.crypto.spec.SecretKeySpec;import java.io.UnsupportedEncodingException;/** * Created by zhangzb on 17-8-2. */public class EncryptGZipUtils &#123; public static final int ACTION_MASK = 255; private static final char[] legalChars = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/".toCharArray(); private static byte[] iv = new byte[]&#123;(byte) 1, (byte) 2, (byte) 3, (byte) 4, (byte) 5, (byte) 6, (byte) 7, (byte) 8&#125;; public static String encode(byte[] data) &#123; int len = data.length; StringBuffer buf = new StringBuffer((data.length * 3) / 2); int end = len - 3; int i = 0; int n = 0; int d; while (i &lt;= end) &#123; d = (((data[i] &amp; ACTION_MASK) &lt;&lt; 16) | ((data[i + 1] &amp; ACTION_MASK) &lt;&lt; 8)) | (data[i + 2] &amp; ACTION_MASK); buf.append(legalChars[(d &gt;&gt; 18) &amp; 63]); buf.append(legalChars[(d &gt;&gt; 12) &amp; 63]); buf.append(legalChars[(d &gt;&gt; 6) &amp; 63]); buf.append(legalChars[d &amp; 63]); i += 3; int n2 = n + 1; if (n &gt;= 14) &#123; n2 = 0; buf.append(" "); &#125; n = n2; &#125; if (i == (0 + len) - 2) &#123; d = ((data[i] &amp; ACTION_MASK) &lt;&lt; 16) | ((data[i + 1] &amp; ACTION_MASK) &lt;&lt; 8); buf.append(legalChars[(d &gt;&gt; 18) &amp; 63]); buf.append(legalChars[(d &gt;&gt; 12) &amp; 63]); buf.append(legalChars[(d &gt;&gt; 6) &amp; 63]); buf.append("="); &#125; else if (i == (0 + len) - 1) &#123; d = (data[i] &amp; ACTION_MASK) &lt;&lt; 16; buf.append(legalChars[(d &gt;&gt; 18) &amp; 63]); buf.append(legalChars[(d &gt;&gt; 12) &amp; 63]); buf.append("=="); &#125; return buf.toString(); &#125; public static byte[] desEncode(String secret, byte[] byteS) &#123; try &#123; IvParameterSpec zeroIv = new IvParameterSpec(iv); SecretKeySpec key = new SecretKeySpec(secret.getBytes(), "DES"); Cipher cipher = Cipher.getInstance("DES/CBC/PKCS5Padding"); cipher.init(1, key, zeroIv); return cipher.doFinal(byteS); &#125; catch (Exception e) &#123; e.printStackTrace(); return null; &#125; &#125; public static void main(String[] args) &#123; String pwd = "82**88"; String secret = "!@#j*&amp;!k"; try &#123; String secretPwd = encode(EncryptGZipUtils.desEncode(secret, pwd.getBytes("UTF-8"))); System.out.println(secretPwd); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>encrypt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java发送邮件工具类]]></title>
    <url>%2FJava%2Fjava-send-mail-util.html</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243package com.zhangzob.util;import lombok.Data;import lombok.extern.slf4j.Slf4j;import org.simplejavamail.email.Email;import org.simplejavamail.mailer.Mailer;import javax.mail.Message;import java.util.List;import java.util.Map;/** * Created by zhangzb on 17-2-10. */@Slf4j@Datapublic class SendEmailUtil &#123; /** * @param map 要发送的消息 * @param toUser 收件人邮箱 */ public static void sendEmail(Map&lt;String, List&lt;String&gt;&gt; map, String toUser)&#123; StringBuilder stringBuilder = new StringBuilder(); for(String value : map.keySet())&#123; stringBuilder.append(value); stringBuilder.append(":"); stringBuilder.append(map.get(value).toString()); stringBuilder.append("\n"); &#125; Email email = new Email(); email.setFromAddress("apiTest", "yourmail@163.com"); email.addRecipient("", toUser, Message.RecipientType.TO); email.setSubject("测试结果"); email.setText(stringBuilder.toString()); new Mailer("smtp.163.com", 25, "yourmail@163.com", "yourPassword").sendMail(email); log.info("发送成功！"); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>mail</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fpost%2Fhello-world.html</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post.Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
